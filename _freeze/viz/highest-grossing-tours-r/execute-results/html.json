{
  "hash": "a9f9cfb9404dbb9329db049d1d38b5ab",
  "result": {
    "markdown": "<details><summary>See R code</summary>\n\n::: {.callout-tip}\n## Highest-grossing tours of all time visualization\n\nLet's get started by loading the necessary R packages to clean, scrape, and visualize the data. These packages are the building blocks of our data scraping journey.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# To clean data\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(janitor)\n\n# To scrape data\nlibrary(rvest)\nlibrary(httr)\nlibrary(polite)\n\n# To visualize data\nlibrary(ggplot2)\nlibrary(showtext)\nlibrary(viridis)\n\nfont_add_google(\"Open Sans\", \"open-sans\")\nshowtext::showtext_auto()\n```\n:::\n\n\nNow that we have the necessary libraries loaded, it's time to politely scrape data from Wikipedia and bring it into R. We'll start by specifying the URL of the Wikipedia page we want to extract data from:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurl <-\n  \"https://en.wikipedia.org/wiki/List_of_highest-grossing_concert_tours\"\n```\n:::\n\n\nNext, we'll use the polite package to create a 'bag of words' (bow) representation of the URL. This step helps us make a polite request to the web server for the page's content:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurl_bow <- polite::bow(url)\nurl_bow\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<polite session> https://en.wikipedia.org/wiki/List_of_highest-grossing_concert_tours\n    User-agent: polite R package\n    robots.txt: 456 rules are defined for 33 bots\n   Crawl delay: 5 sec\n  The path is scrapable for this user-agent\n```\n\n\n:::\n:::\n\n\nOnce we have our 'bow,' we can use it to scrape the web page. We'll specifically target the tables with the class 'wikitable' on the page:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nind_html <-\n  polite::scrape(url_bow) %>%  # scrape web page\n  rvest::html_nodes(\"table.wikitable\") %>% # pull out specific table\n  rvest::html_table(fill = TRUE) \n```\n:::\n\n\nFinally, we'll clean up the extracted table (the second table on the page, Top 20 highest-grossing tours of all time) by storing it in the `ind_tab` variable and ensuring that column names are in a consistent format:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nind_tab <- \n  ind_html[[2]] %>% \n  clean_names()\n```\n:::\n\n\nThis code segment efficiently fetches and prepares the data we need from the Wikipedia page. Our next step is to clean it for analysis. In this code snippet, we'll perform some essential data cleaning tasks to make our dataset ready for exploration: transforming the Adjusted Gross in 2022 Dollars, Actual Gross, and Average Gross columns into numeric variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nind_tab_clean <-\n  ind_tab %>%\n  dplyr::mutate(across(\n    c(adjusted_gross_in_2022_dollars,\n      actual_gross,\n      averagegross),\n    ~ as.numeric(str_replace_all(.x, \"[$,]\", \"\"))\n  ))\n```\n:::\n\n\nWe want to add Taylor's data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nind_tab_tay <-\n  ind_tab_clean %>% \n  add_row(artist = \"Taylor Swift\",\n          tour_title = \"The Eras Tour (Expected)\",\n          year_s = \"2023-2024\",\n          shows = 146,\n          adjusted_gross_in_2022_dollars = 1400000000)\n```\n:::\n\n\n\nNow that our data is clean and ready, let's visualize the highest-grossing concert tours of all time (as of 2023) using a bar chart. We'll use the ggplot2 package\n\n\n::: {.cell}\n\n```{.r .cell-code}\nind_tab_tay %>%\n  mutate(color = case_when(artist == \"Taylor Swift\" ~ \"#C2D9D9\",\n                          .default = \"#122B2B\")) %>% \n  ggplot(aes(\n    x = forcats::fct_reorder(tour_title, adjusted_gross_in_2022_dollars),\n    y = adjusted_gross_in_2022_dollars\n  )) +\n  geom_col(aes(fill = color),\n           color = \"#122B2B\",\n           width= .9) +\n  scale_fill_identity() +\n  labs(title = \"Highest-grossing tours of all time\",\n       subtitle = \"(as of 2023)\") +\n  theme(\n    text = element_text(size = 9,\n                        family = \"open-sans\"),\n    title = element_text(size = 16,\n                              face = \"bold\",\n                              family = \"open-sans\"),\n    subtitle = element_text(size = 12,\n                                 family = \"open-sans\")\n  ) +\n  geom_text(aes(y = 12000000, label = tour_title),\n  family = \"open-sans\",\n  hjust = 0,\n  vjust = 0.5,\n  size = 3,\n  color = \"white\",\n  fontface = \"bold\") +\n    geom_text(aes(y = 12000000, label = ifelse(artist == \"Taylor Swift\", tour_title, \"\")),\n  family = \"open-sans\",\n  hjust = 0,\n  vjust = 0.5,\n  size = 3,\n  color = \"black\",\n  fontface = \"bold\") +\n  geom_text(aes(\n    label = scales::dollar(\n      adjusted_gross_in_2022_dollars,\n      accuracy = 1,\n      scale = 1e-6,\n      suffix = \"M\"\n    )\n  ),\n  family = \"open-sans\",\n  hjust = -0.1,\n  vjust = 0.5,\n  size = 3) +\n  coord_flip() +\n  scale_y_continuous(limits = c(0, 1500000000)) +\n  theme_void()\n```\n:::\n\n\n:::\n</details>",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}