[
  {
    "objectID": "notebooks/highest-grossing-tours-r.html",
    "href": "notebooks/highest-grossing-tours-r.html",
    "title": "",
    "section": "",
    "text": "See R code\n\n\n\n\n\n\n\nHighest-grossing tours of all time visualization\n\n\n\nLet’s get started by loading the necessary R packages to clean, scrape, and visualize the data. These packages are the building blocks of our data scraping journey.\n\n# To clean data\nlibrary(tidyverse)\nlibrary(janitor)\n\n# To scrape data\nlibrary(rvest)\nlibrary(httr)\nlibrary(polite)\n\n# To visualize data\nlibrary(ggplot2)\nlibrary(showtext)\nlibrary(viridis)\n\nfont_add_google(\"Playfair Display\", \"playfair-display\")\nfont_add_google(\"Lato\", \"lato\")\n\nshowtext::showtext_auto()\n\nNow that we have the necessary libraries loaded, it’s time to politely scrape data from Wikipedia and bring it into R. We’ll start by specifying the URL of the Wikipedia page we want to extract data from:\n\nurl &lt;-\n  \"https://en.wikipedia.org/wiki/List_of_highest-grossing_concert_tours\"\n\nNext, we’ll use the polite package to create a ‘bag of words’ (bow) representation of the URL. This step helps us make a polite request to the web server for the page’s content:\n\nurl_bow &lt;- polite::bow(url)\nurl_bow\n\n&lt;polite session&gt; https://en.wikipedia.org/wiki/List_of_highest-grossing_concert_tours\n    User-agent: polite R package\n    robots.txt: 456 rules are defined for 33 bots\n   Crawl delay: 5 sec\n  The path is scrapable for this user-agent\n\n\nOnce we have our ‘bow,’ we can use it to scrape the web page. We’ll specifically target the tables with the class ‘wikitable’ on the page:\n\nind_html &lt;-\n  polite::scrape(url_bow) |&gt;  # scrape web page\n  rvest::html_nodes(\"table.wikitable\") |&gt; # pull out specific table\n  rvest::html_table(fill = TRUE) \n\nFinally, we’ll clean up the extracted table (the second table on the page, Top 20 highest-grossing tours of all time) by storing it in the ind_tab variable and ensuring that column names are in a consistent format:\n\nind_tab &lt;- \n  ind_html[[2]] |&gt; \n  clean_names()\n\nThis code segment efficiently fetches and prepares the data we need from the Wikipedia page. Our next step is to clean it for analysis. In this code snippet, we’ll perform some essential data cleaning tasks to make our dataset ready for exploration: transforming the Adjusted Gross in 2022 Dollars, Actual Gross, and Average Gross columns into numeric variables.\n\nind_tab_clean &lt;-\n  ind_tab |&gt;\n  dplyr::mutate(across(\n    c(adjusted_gross_in_2022_dollars,\n      actual_gross,\n      averagegross),\n    ~ as.numeric(str_replace_all(.x, \"[$,]\", \"\"))\n  ))\n\nWe want to add Taylor’s data:\n\nind_tab_tay &lt;-\n  ind_tab_clean |&gt; \n  add_row(artist = \"Taylor Swift\",\n          tour_title = \"The Eras Tour (Expected)\",\n          year_s = \"2023-2024\",\n          shows = 146,\n          adjusted_gross_in_2022_dollars = 1400000000,\n          .before = 1)\n\nNow that our data is clean and ready, let’s visualize the highest-grossing concert tours of all time (as of 2023) using a bar chart. We’ll use the ggplot2 package.\n\nind_tab_tay |&gt;\n  slice(1:10) |&gt; \n  mutate(color = case_when(artist == \"Taylor Swift\" ~ \"#D3ABD0\",\n                           .default = \"#903345\")) |&gt;\n  ggplot(aes(\n    x = forcats::fct_reorder(tour_title,\n                             adjusted_gross_in_2022_dollars),\n    y = adjusted_gross_in_2022_dollars\n  )) +\n  geom_col(aes(fill = color),\n           color = \"black\",\n           width = .9) +\n  scale_fill_identity() +\n  labs(title = \"Highest-grossing tours of all time\",\n       subtitle = \"(as of 2023)\") +\n  theme(\n    text = element_text(size = 9,\n                        family = \"lato\"),\n    title = element_text(\n      size = 16,\n      family = \"playfair-display\"\n    ),\n    subtitle = element_text(size = 12,\n                            family = \"lato\")\n  ) +\n  geom_text(\n    aes(y = 12000000, label = tour_title),\n    family = \"lato\",\n    hjust = 0,\n    vjust = 0.5,\n    size = 3,\n    color = \"white\",\n    fontface = \"bold\"\n  ) +\n  geom_text(\n    aes(\n      y = 12000000,\n      label = ifelse(artist == \"Taylor Swift\", tour_title, \"\")\n    ),\n    family = \"lato\",\n    hjust = 0,\n    vjust = 0.5,\n    size = 3,\n    color = \"black\",\n    fontface = \"bold\"\n  ) +\n  geom_text(\n    aes(\n      label = scales::dollar(\n        adjusted_gross_in_2022_dollars,\n        accuracy = 1,\n        scale = 1e-6,\n        suffix = \"M\"\n      )\n    ),\n    family = \"lato\",\n    hjust = -0.1,\n    vjust = 0.5,\n    size = 3\n  ) +\n  coord_flip() +\n  scale_y_continuous(limits = c(0, 1500000000)) +\n  theme_void()"
  },
  {
    "objectID": "notebooks/highest-gross-tours-decade-r.html",
    "href": "notebooks/highest-gross-tours-decade-r.html",
    "title": "",
    "section": "",
    "text": "See R code\n\n\n\n\n\n\n\nTip\n\n\n\n\ncombine_data &lt;- function(ind_html_list) {\n  # Initialize an empty tibble\n  combined_data &lt;- tibble()\n  \n  # Loop through the ind_html_list and append each element to the combined_data\n  for (i in 4:8) {\n    extracted_data &lt;- ind_html_list[[i]] |&gt; clean_names()\n    combined_data &lt;- bind_rows(combined_data, extracted_data)\n  }\n  \n  return(combined_data)\n}\n\nannual_hi_gross_tours &lt;- combine_data(ind_html)\n\n\ntours_by_decade &lt;-\n  annual_hi_gross_tours |&gt;\n  dplyr::mutate(across(\n    c(adjusted_gross_in_2022_dollar,\n      averagegross,\n      actual_gross),\n    ~ as.numeric(str_replace_all(.x, \"[$,]\", \"\"))\n  )) |&gt;\n     add_row(artist = \"Taylor Swift\",\n          tour_title = \"The Eras Tour (Expected)\",\n          year_s = \"2023-2024\",\n          shows = 146,\n          adjusted_gross_in_2022_dollar = 1400000000) |&gt; \n  mutate(\n    start_year = str_sub(year_s, start = 1, end = 4),\n    year = lubridate::ymd(start_year, truncated = 2L)) |&gt; \n  mutate(decade = as.factor(floor_date(year, years(10))))\n\n\ng1 &lt;- subset(tours_by_decade, tour_title == \"The Eras Tour (Expected)\")\n\ntours_by_decade |&gt;\n  ggplot(aes(\n    x = year,\n    y = adjusted_gross_in_2022_dollar,\n    size =  shows,\n    fill = decade\n  )) +\n  geom_point(alpha = 0.5,\n             shape = 21,\n             color = \"black\") +\n  scale_size(range = c(.1, 8)) +\n  scale_fill_viridis(discrete = TRUE,\n                     guide = FALSE,\n                     option = \"G\") +\n  theme_minimal() +\n  geom_point(data = g1, colour = \"#122B2B\") +\n  geom_text(\n    data = g1,\n    label = \"Taylor Swift\",\n    vjust = 2.4,\n    size = 3\n  ) +\n  theme(legend.position = \"none\") +\n  labs(title = \"Highest-grossing tours by decade\") +\n  scale_x_date(limits = c(ymd(\"1980-01-01\"), ymd(\"2028-01-01\")))\n\n\n\n\n\ntours_by_decade |&gt; \n  ggplot(aes(x = shows, y = adjusted_gross_in_2022_dollar)) +\n  geom_point()\n\n\n\n\n\ntours_by_decade |&gt; \n  ggplot(aes(x = shows, y = adjusted_gross_in_2022_dollar)) +\n  geom_point()"
  },
  {
    "objectID": "notebooks/get-songstats-data.html",
    "href": "notebooks/get-songstats-data.html",
    "title": "",
    "section": "",
    "text": "See R code\n\n\n\n\n\n\n\nTip\n\n\n\n\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(purrr)\nlibrary(readr)\nlibrary(glue)\n\nget_artist_data &lt;- function(artist_name, songstats_artist_id) {\n  url &lt;-\n    \"https://api.songstats.com/enterprise/v1/artists/historic_stats\"\n  \n  queryString &lt;- list(\n    source = \"all\",\n    songstats_artist_id = songstats_artist_id,\n    start_date = \"2020-01-01\"\n  )\n  \n  response &lt;- httr::VERB(\n    \"GET\",\n    url,\n    query = queryString,\n    add_headers(\n      \"Accept-Encoding\" = \"\",\n      \"apikey\" = Sys.getenv(\"SONGSTATS_TOKEN\")\n    ),\n    content_type(\"application/octet-stream\"),\n    accept(\"application/json\")\n  )\n  \n  artist_data &lt;- httr::content(response, \"text\")\n  \n  artist_tibble &lt;- artist_data |&gt;\n    jsonlite::fromJSON() |&gt;\n    purrr::map_if(is.data.frame, list) |&gt;\n    as.data.frame() |&gt;\n    tidyr::unnest_wider(stats.data) |&gt;\n    tidyr::unnest(history) |&gt;\n    dplyr::mutate(\n      time_frame = dplyr::case_when(date &lt; \"2022-11-01\" ~ \"before announcement\",\n                                    .default = \"after announcement\"),\n      artist = artist_name\n    )\n  \n  file_name &lt;- glue::glue(\"{artist_name}_tibble.Rds\")\n  readr::write_rds(artist_tibble, \"data/file_name\")\n  \n  return(artist_tibble)\n}\n\n# Create a list of artists and their IDs\nartists &lt;- list(\n  c(\"Paramore\", \"p5xm8h7b\"),\n  c(\"Beabadoobee\", \"n3k29evr\"),\n  c(\"Phoebe Bridgers\", \"9yhbd1el\"),\n  c(\"Girl In Red\", \"p71m4gr8\"),\n  c(\"MUNA\", \"fyxmowt5\"),\n  c(\"HAIM\", \"apuz50ix\"),\n  c(\"GAYLE\", \"q16uf7gk\"),\n  c(\"OWENN\", \"cztp0nug\"),\n  c(\"Gracie Abrams\", \"so4cd0bt\"),\n  c(\"Taylor Swift\", \"i5muw4xf\")\n)\n\nartist_data_list &lt;-\n  map(artists, ~ get_artist_data(.x[1], .x[2]))\n\ncombined_artist_data &lt;-\n  bind_rows(artist_data_list)\n\nwrite_rds(combined_artist_data, \"data/combined_artist_data.rds\")"
  },
  {
    "objectID": "notebooks/taylor-music.html",
    "href": "notebooks/taylor-music.html",
    "title": "",
    "section": "",
    "text": "library(dplyr)\nlibrary(readr)\nlibrary(tidyr)\nlibrary(gt)\nlibrary(gtExtras)\nlibrary(ggplot2)\n\ntaylor &lt;-\n  read_rds(\"data/combined_artist_data.rds\") |&gt; \n  filter(artist == \"Taylor Swift\",\n         stats.source == \"spotify\") |&gt; \n  mutate(date = as.Date(date)) |&gt; \n  pivot_longer(cols = followers_total:monthly_listeners_current)\n\ntaylor |&gt;\n  group_by(name) |&gt;\n  dplyr::summarize(spotify_data = list(value),\n                   .groups = \"drop\") |&gt;\n  gt() |&gt;\n  gt_plt_sparkline(spotify_data)\n\ntaylor |&gt;\n  ggplot(aes(x = date, y = value, group = name)) + geom_line() +\n  facet_grid(~ name)"
  },
  {
    "objectID": "notebooks/eras-tour-dates-and-venues.html",
    "href": "notebooks/eras-tour-dates-and-venues.html",
    "title": "",
    "section": "",
    "text": "See R code\n\n\n\n\n\n\n\nThe Eras Tour Dates and Venues\n\n\n\n\n# To clean data\nlibrary(tidyverse)\nlibrary(janitor)\n\n# To scrape data\nlibrary(rvest)\nlibrary(httr)\nlibrary(polite)\n\n# To geocode data\nlibrary(tidygeocoder)\n\n# To visualize data\nlibrary(leaflet)\n\n\nurl_map &lt;-\n  \"https://www.sportskeeda.com/pop-culture/taylor-swift-2023-the-eras-tour-ticket-cities-and-dates\"\n\nurl_map_bow &lt;- polite::bow(url_map)\nurl_map_bow\n\n&lt;polite session&gt; https://www.sportskeeda.com/pop-culture/taylor-swift-2023-the-eras-tour-ticket-cities-and-dates\n    User-agent: polite R package\n    robots.txt: 41 rules are defined for 4 bots\n   Crawl delay: 5 sec\n  The path is scrapable for this user-agent\n\n\n\nmap_html &lt;-\n  polite::scrape(url_map_bow) |&gt;  # scrape web page\n  rvest::html_nodes(\"tbody\") |&gt; # pull out specific table\n  rvest::html_table(fill = TRUE) |&gt;\n  bind_rows() |&gt;\n  row_to_names(row_number = 1) |&gt;\n  clean_names()\n\n\nmap_html_geocode &lt;-\n  map_html |&gt;\n  geocode(venue,\n          method = \"osm\",\n          lat = latitude ,\n          long = longitude)\n\nmap_html_geo &lt;-\n  map_html_geocode |&gt;\n  mutate(\n    latitude = case_when(\n      venue == \"Empower Field at Mile Hi\" ~ 39.74359,\n      venue == \"Johan Cruyff Arena\" ~ 52.3143,\n      .default = latitude\n    ),\n    longitude = case_when(\n      venue == \"Empower Field at Mile Hi\" ~ -105.01968,\n      venue == \"Johan Cruyff Arena\" ~ 4.94187,\n      .default = longitude\n    )\n  ) |&gt;\n  mutate(number_shows = n(),\n         .by = c(venue, city)) |&gt;\n  mutate(occurred = case_when(lubridate::mdy(paste0(date, year)) &lt; today() ~ \"Occurred\",\n                              .default = \"Not Occurred\"))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `occurred = case_when(...)`.\nCaused by warning:\n!  24 failed to parse.\n\n\n\npal &lt;- colorFactor(\n  palette = c(\"#823549\", \"#1D1F38\"),\n  domain = map_html_geo$occurred\n)\n\nleaflet(options = leafletOptions(minZoom = 10, maxZoom = 10)) |&gt;\n  addProviderTiles(\"Esri.WorldGrayCanvas\",\n                   options = (noWrap = TRUE)) |&gt;\n  setMaxBounds(\n    lng1 = 180,\n    lat1 = 90,\n    lng2 = -180,\n    lat2 = -90\n  ) |&gt; \n  addCircleMarkers(\n    data = map_html_geo,\n    color = ~pal(occurred),\n    label = paste(\n      \"Venue: \",\n      map_html_geo$venue,\n      \"&lt;br&gt;\",\n      \"City: \",\n      map_html_geo$city,\n      \"&lt;br&gt;\",\n      \"Number of Shows: \",\n      map_html_geo$number_shows\n    ) |&gt;\n      lapply(htmltools::HTML)\n  ) |&gt; \n  addLegend(\"bottomright\", pal = pal, values = map_html_geo$occurred,\n    title = \"Event Status\",\n    opacity = 1\n  )"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Taylor Swift’s Tour in the Pantheon of Music",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula. Aliquam sit amet ipsum ut nisl gravida molestie. Morbi orci tortor, dapibus a dictum vitae, congue sit amet lorem. Praesent purus risus, auctor ac neque sed, interdum feugiat erat. Fusce gravida pellentesque lacus, eget sodales elit sodales vitae. Nunc porttitor pulvinar bibendum.\n\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula. Aliquam sit amet ipsum ut nisl gravida molestie. Morbi orci tortor, dapibus a dictum vitae, congue sit amet lorem. Praesent purus risus, auctor ac neque sed, interdum feugiat erat. Fusce gravida pellentesque lacus, eget sodales elit sodales vitae. Nunc porttitor pulvinar bibendum.\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\n\n\n\n\n\n\n\n\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\n\n\n\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula."
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Taylor Swift’s Tour in the Pantheon of Music",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula. Aliquam sit amet ipsum ut nisl gravida molestie. Morbi orci tortor, dapibus a dictum vitae, congue sit amet lorem. Praesent purus risus, auctor ac neque sed, interdum feugiat erat. Fusce gravida pellentesque lacus, eget sodales elit sodales vitae. Nunc porttitor pulvinar bibendum."
  },
  {
    "objectID": "index.html#openers",
    "href": "index.html#openers",
    "title": "Taylor Swift’s Tour in the Pantheon of Music",
    "section": "Openers",
    "text": "Openers\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "py.html",
    "href": "py.html",
    "title": "Taylor Swift’s Tour in the Pantheon of Music",
    "section": "",
    "text": "[to be added]",
    "crumbs": [
      "Want to walk through the code?",
      "🐍 See the code in Python"
    ]
  },
  {
    "objectID": "r.html",
    "href": "r.html",
    "title": "Taylor Swift’s Tour in the Pantheon of Music",
    "section": "",
    "text": "[to be added]",
    "crumbs": [
      "Want to walk through the code?",
      "🔵 See the code in R"
    ]
  },
  {
    "objectID": "notebooks/opener-data.html",
    "href": "notebooks/opener-data.html",
    "title": "",
    "section": "",
    "text": "Attaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "notebooks/annual-highest-grossing-tours-r.html",
    "href": "notebooks/annual-highest-grossing-tours-r.html",
    "title": "",
    "section": "",
    "text": "See R code\n\n\n\n\n\n\n\nTip\n\n\n\n\nannual_hi_gross_tours &lt;-\n  ind_html[[9]] |&gt;\n  clean_names()\n\n\nannual_hi_gross_tours_clean &lt;-\n  annual_hi_gross_tours |&gt;\n  dplyr::mutate(across(\n    c(adjusted_gross_in_2022_dollar,\n      actual_gross),\n    ~ as.numeric(str_replace_all(.x, \"[$,]\", \"\"))\n  ),\n  year = lubridate::ymd(year, truncated = 2L),\n  decade = as.factor(floor_date(year, years(10)))) |&gt; \n  add_row(artist = \"Taylor Swift\",\n          tour_title = \"The Eras Tour (Expected)\",\n          year = lubridate::date(\"2023-01-01\"),\n          shows = 146,\n          adjusted_gross_in_2022_dollar = 1400000000,\n          decade = \"2020-01-01\",\n          .before = 1)\n\n\nannual_hi_gross_tours_clean |&gt;\n  ggplot(aes(\n    x = year,\n    y = adjusted_gross_in_2022_dollar,\n    fill = decade\n  )) +\n  geom_bar(stat = \"identity\") +\n  geom_smooth(aes(group = decade)) +\n  scale_size(range = c(0, 4)) +\n  theme_minimal() +\n  theme(\n    text = element_text(size = 9,\n                        family = \"lato\"),\n    title = element_text(size = 16,\n                         family = \"abril-fatface\"),\n    panel.background = element_blank(),\n    axis.ticks.x = element_blank(),\n    axis.text.x = element_blank(),\n    axis.title.x = element_blank(),\n    axis.title.y = element_blank()) +\n  geom_text(aes(label = tour_title),\n            family = \"lato\",\n            vjust = -2.5,\n            angle = 45,\n            size = 2) +\n  labs(title = \"Annual highest-grossing tours\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: span too small.  fewer data values than degrees of freedom.\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: at 6205.3\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: radius 13.359\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: all data on boundary of neighborhood. make span bigger\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: pseudoinverse used at 6205.3\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: neighborhood radius 3.655\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: reciprocal condition number 1\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: at 6943.7\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: radius 13.359\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: all data on boundary of neighborhood. make span bigger\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: There are other near singularities as well. 13.359\n\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: zero-width neighborhood. make span bigger\n\nWarning in simpleLoess(y, x, w, span, degree = degree, parametric = parametric,\n: zero-width neighborhood. make span bigger\n\n\nWarning: Computation failed in `stat_smooth()`\nCaused by error in `predLoess()`:\n! NA/NaN/Inf in foreign function call (arg 5)\n\n\n\nannual_hi_gross_tours_clean |&gt;\n  ggplot(aes(\n    x = shows,\n    y = adjusted_gross_in_2022_dollar,\n    fill = decade\n  )) +\n  geom_point(alpha = 0.5,\n             shape = 21,\n             color = \"black\") +\n  scale_size(range = c(0, 4)) +\n  scale_fill_viridis(discrete = TRUE,\n                     guide = FALSE,\n                     option = \"A\") +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    text = element_text(size = 9,\n                        family = \"lato\"),\n    title = element_text(size = 16,\n                         family = \"abril-fatface\"),\n    panel.background = element_blank(),\n    axis.ticks.x = element_blank(),\n    axis.title.x = element_blank(),\n    axis.title.y = element_blank()\n  ) +\n  labs(title = \"Number of shows vs. income\")"
  },
  {
    "objectID": "notebooks/cost-per-ticket.html",
    "href": "notebooks/cost-per-ticket.html",
    "title": "",
    "section": "",
    "text": "url2 &lt;-\n  \"https://en.wikipedia.org/wiki/List_of_most-attended_concert_tours\"\n\nurl_bow2 &lt;- polite::bow(url2)\nurl_bow2\n\n&lt;polite session&gt; https://en.wikipedia.org/wiki/List_of_most-attended_concert_tours\n    User-agent: polite R package\n    robots.txt: 456 rules are defined for 33 bots\n   Crawl delay: 5 sec\n  The path is scrapable for this user-agent\n\nind_html2 &lt;-\n  polite::scrape(url_bow2) |&gt;  # scrape web page\n  rvest::html_nodes(\"table.wikitable\") |&gt; # pull out specific table\n  rvest::html_table(fill = TRUE)\n\nind_tab2 &lt;-\n  ind_html2[[2]] |&gt;\n  janitor::clean_names() |&gt;\n  dplyr::mutate(tickets_sold = as.numeric(str_replace(tickets_sold, \" million.*\", \"\")) * 1e6)\n\ntours_by_decade2 &lt;-\n  tours_by_decade |&gt;\n  dplyr::mutate(\n    tour_title = case_when(\n      tour_title == \"Music of the Spheres World Tour †\" ~ \"Music of the Spheres World Tour\",\n      tour_title == \"The Garth Brooks World Tour\" ~ \"The Garth Brooks World Tour (1996–1998)\",\n      tour_title == \"Steel Wheels Tour\" ~ \"Steel Wheels/Urban Jungle Tour\",\n      .default = tour_title\n    )\n  )\n\ncost_per &lt;-\n  left_join(ind_tab2, tours_by_decade2, join_by(tour_title))\n\n\ncost_per |&gt;\n  mutate(cost_per = adjusted_gross_in_2022_dollar / tickets_sold) |&gt;\n  ggplot(aes(x = year, y = cost_per)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 1 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 1 rows containing missing values (`geom_point()`)."
  }
]