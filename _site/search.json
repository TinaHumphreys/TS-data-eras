[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Taylor Swift’s Tour in the Pantheon of Music",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula. Aliquam sit amet ipsum ut nisl gravida molestie. Morbi orci tortor, dapibus a dictum vitae, congue sit amet lorem. Praesent purus risus, auctor ac neque sed, interdum feugiat erat. Fusce gravida pellentesque lacus, eget sodales elit sodales vitae. Nunc porttitor pulvinar bibendum.\n\n\n\n\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula. Aliquam sit amet ipsum ut nisl gravida molestie. Morbi orci tortor, dapibus a dictum vitae, congue sit amet lorem. Praesent purus risus, auctor ac neque sed, interdum feugiat erat. Fusce gravida pellentesque lacus, eget sodales elit sodales vitae. Nunc porttitor pulvinar bibendum.\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\n\n\n\n\n\n\nAssuming \"longitude\" and \"latitude\" are longitude and latitude, respectively\n\n\n\n\n\n\n\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\n\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\n\n\n\n\n\n\n\nannual_hi_gross_tours &lt;-\n  ind_html[[9]] %&gt;%\n  clean_names()\n\n\nannual_hi_gross_tours_clean &lt;-\n  annual_hi_gross_tours %&gt;%\n  dplyr::mutate(across(\n    c(adjusted_gross_in_2022_dollar,\n      actual_gross),\n    ~ as.numeric(str_replace_all(.x, \"[$,]\", \"\"))\n  ),\n  year = lubridate::ymd(year, truncated = 2L),\n  decade = as.factor(floor_date(year, years(10))))\n\n\nannual_hi_gross_tours_clean %&gt;%\n  ggplot(aes(\n    x = year,\n    y = adjusted_gross_in_2022_dollar,\n    size =  shows,\n    fill = decade\n  )) +\n  geom_point(alpha = 0.5,\n             shape = 21,\n             color = \"black\") +\n  scale_size(range = c(.1, 8)) +\n  scale_fill_viridis(discrete = TRUE, guide = FALSE, option = \"A\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  labs(title = \"Annual highest-grossing tours\")"
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "Taylor Swift’s Tour in the Pantheon of Music",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula. Aliquam sit amet ipsum ut nisl gravida molestie. Morbi orci tortor, dapibus a dictum vitae, congue sit amet lorem. Praesent purus risus, auctor ac neque sed, interdum feugiat erat. Fusce gravida pellentesque lacus, eget sodales elit sodales vitae. Nunc porttitor pulvinar bibendum."
  },
  {
    "objectID": "index.html#the-eras-tour",
    "href": "index.html#the-eras-tour",
    "title": "Taylor Swift’s Tour in the Pantheon of Music",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula. Aliquam sit amet ipsum ut nisl gravida molestie. Morbi orci tortor, dapibus a dictum vitae, congue sit amet lorem. Praesent purus risus, auctor ac neque sed, interdum feugiat erat. Fusce gravida pellentesque lacus, eget sodales elit sodales vitae. Nunc porttitor pulvinar bibendum.\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\n\n\n\n\n\n\nAssuming \"longitude\" and \"latitude\" are longitude and latitude, respectively\n\n\n\n\n\n\n\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\n\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\n\n\n\n\n\n\n\nannual_hi_gross_tours &lt;-\n  ind_html[[9]] %&gt;%\n  clean_names()\n\n\nannual_hi_gross_tours_clean &lt;-\n  annual_hi_gross_tours %&gt;%\n  dplyr::mutate(across(\n    c(adjusted_gross_in_2022_dollar,\n      actual_gross),\n    ~ as.numeric(str_replace_all(.x, \"[$,]\", \"\"))\n  ),\n  year = lubridate::ymd(year, truncated = 2L),\n  decade = as.factor(floor_date(year, years(10))))\n\n\nannual_hi_gross_tours_clean %&gt;%\n  ggplot(aes(\n    x = year,\n    y = adjusted_gross_in_2022_dollar,\n    size =  shows,\n    fill = decade\n  )) +\n  geom_point(alpha = 0.5,\n             shape = 21,\n             color = \"black\") +\n  scale_size(range = c(.1, 8)) +\n  scale_fill_viridis(discrete = TRUE, guide = FALSE, option = \"A\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  labs(title = \"Annual highest-grossing tours\")"
  },
  {
    "objectID": "index.html#annual-highest-grossing-tours",
    "href": "index.html#annual-highest-grossing-tours",
    "title": "Taylor Swift’s Tour in the Pantheon of Music",
    "section": "",
    "text": "annual_hi_gross_tours &lt;-\n  ind_html[[9]] %&gt;%\n  clean_names()\n\n\nannual_hi_gross_tours_clean &lt;-\n  annual_hi_gross_tours %&gt;%\n  dplyr::mutate(across(\n    c(adjusted_gross_in_2022_dollar,\n      actual_gross),\n    ~ as.numeric(str_replace_all(.x, \"[$,]\", \"\"))\n  ),\n  year = lubridate::ymd(year, truncated = 2L),\n  decade = as.factor(floor_date(year, years(10))))\n\n\nannual_hi_gross_tours_clean %&gt;%\n  ggplot(aes(\n    x = year,\n    y = adjusted_gross_in_2022_dollar,\n    size =  shows,\n    fill = decade\n  )) +\n  geom_point(alpha = 0.5,\n             shape = 21,\n             color = \"black\") +\n  scale_size(range = c(.1, 8)) +\n  scale_fill_viridis(discrete = TRUE, guide = FALSE, option = \"A\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  labs(title = \"Annual highest-grossing tours\")"
  },
  {
    "objectID": "index.html#locations-of-taylor-swift-tours",
    "href": "index.html#locations-of-taylor-swift-tours",
    "title": "Taylor Swift’s Tour in the Pantheon of Music",
    "section": "Locations of Taylor Swift Tours",
    "text": "Locations of Taylor Swift Tours"
  },
  {
    "objectID": "highest-grossing-tours.html",
    "href": "highest-grossing-tours.html",
    "title": "",
    "section": "",
    "text": "Let’s get started by loading the necessary R packages to clean, scrape, and visualize the data. These packages are the building blocks of our data scraping journey.\n\n# To clean data\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(janitor)\n\n# To scrape data\nlibrary(rvest)\nlibrary(httr)\nlibrary(polite)\n\n# To visualize data\nlibrary(ggplot2)\nlibrary(showtext)\nlibrary(viridis)\n\nfont_add_google(\"Open Sans\", \"open-sans\")\nshowtext::showtext_auto()\n\nNow that we have the necessary libraries loaded, it’s time to politely scrape data from Wikipedia and bring it into R. We’ll start by specifying the URL of the Wikipedia page we want to extract data from:\n\nurl &lt;- \"https://en.wikipedia.org/wiki/List_of_highest-grossing_concert_tours\"\n\nNext, we’ll use the polite package to create a ‘bag of words’ (bow) representation of the URL. This step helps us make a polite request to the web server for the page’s content:\n\nurl_bow &lt;- polite::bow(url)\nurl_bow\n\n&lt;polite session&gt; https://en.wikipedia.org/wiki/List_of_highest-grossing_concert_tours\n    User-agent: polite R package\n    robots.txt: 456 rules are defined for 33 bots\n   Crawl delay: 5 sec\n  The path is scrapable for this user-agent\n\n\nOnce we have our ‘bow,’ we can use it to scrape the web page. We’ll specifically target the tables with the class ‘wikitable’ on the page:\n\nind_html &lt;-\n  polite::scrape(url_bow) %&gt;%  # scrape web page\n  rvest::html_nodes(\"table.wikitable\") %&gt;% # pull out specific table\n  rvest::html_table(fill = TRUE) \n\nFinally, we’ll clean up the extracted table (the second table on the page, Top 20 highest-grossing tours of all time) by storing it in the ind_tab variable and ensuring that column names are in a consistent format:\n\nind_tab &lt;- \n  ind_html[[2]] %&gt;% \n  clean_names()\n\nThis code segment efficiently fetches and prepares the data we need from the Wikipedia page. Our next step is to clean it for analysis. In this code snippet, we’ll perform some essential data cleaning tasks to make our dataset ready for exploration: transforming the Adjusted Gross in 2022 Dollars, Actual Gross, and Average Gross columns into numeric variables.\n\nind_tab_clean &lt;-\n  ind_tab %&gt;%\n  dplyr::mutate(across(\n    c(adjusted_gross_in_2022_dollars,\n      actual_gross,\n      averagegross),\n    ~ as.numeric(str_replace_all(.x, \"[$,]\", \"\"))\n  ))\n\nWe want to add Taylor’s data\n\nind_tab_tay &lt;-\n  ind_tab_clean %&gt;% \n  add_row(artist = \"Taylor Swift\",\n          tour_title = \"The Eras Tour (Expected)\",\n          year_s = \"2023-2024\",\n          shows = 146,\n          adjusted_gross_in_2022_dollars = 1400000000)\n\nNow that our data is clean and ready, let’s visualize the highest-grossing concert tours of all time (as of 2023) using a bar chart. We’ll use the ggplot2 package\n\nind_tab_tay %&gt;%\n  mutate(color = case_when(artist == \"Taylor Swift\" ~ \"#C2D9D9\",\n                          .default = \"#122B2B\")) %&gt;% \n  ggplot(aes(\n    x = forcats::fct_reorder(tour_title, adjusted_gross_in_2022_dollars),\n    y = adjusted_gross_in_2022_dollars\n  )) +\n  geom_col(aes(fill = color),\n           color = \"#122B2B\",\n           width= .9) +\n  scale_fill_identity() +\n  labs(title = \"Highest-grossing tours of all time\",\n       subtitle = \"(as of 2023)\") +\n  theme(\n    text = element_text(size = 9,\n                        family = \"open-sans\"),\n    title = element_text(size = 16,\n                              face = \"bold\",\n                              family = \"open-sans\"),\n    subtitle = element_text(size = 12,\n                                 family = \"open-sans\")\n  ) +\n  geom_text(aes(y = 12000000, label = tour_title),\n  family = \"open-sans\",\n  hjust = 0,\n  vjust = 0.5,\n  size = 3,\n  color = \"white\",\n  fontface = \"bold\") +\n    geom_text(aes(y = 12000000, label = ifelse(artist == \"Taylor Swift\", tour_title, \"\")),\n  family = \"open-sans\",\n  hjust = 0,\n  vjust = 0.5,\n  size = 3,\n  color = \"black\",\n  fontface = \"bold\") +\n  geom_text(aes(\n    label = scales::dollar(\n      adjusted_gross_in_2022_dollars,\n      accuracy = 1,\n      scale = 1e-6,\n      suffix = \"M\"\n    )\n  ),\n  family = \"open-sans\",\n  hjust = -0.1,\n  vjust = 0.5,\n  size = 3) +\n  coord_flip() +\n  scale_y_continuous(limits = c(0, 1500000000)) +\n  theme_void()"
  },
  {
    "objectID": "viz/highest-grossing-tours-r.html",
    "href": "viz/highest-grossing-tours-r.html",
    "title": "",
    "section": "",
    "text": "See R code\n\n\n\n\n\n\n\nHighest-grossing tours of all time visualization\n\n\n\nLet’s get started by loading the necessary R packages to clean, scrape, and visualize the data. These packages are the building blocks of our data scraping journey.\n\n# To clean data\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(janitor)\n\n# To scrape data\nlibrary(rvest)\nlibrary(httr)\nlibrary(polite)\n\n# To visualize data\nlibrary(ggplot2)\nlibrary(showtext)\nlibrary(viridis)\n\nfont_add_google(\"Open Sans\", \"open-sans\")\nshowtext::showtext_auto()\n\nNow that we have the necessary libraries loaded, it’s time to politely scrape data from Wikipedia and bring it into R. We’ll start by specifying the URL of the Wikipedia page we want to extract data from:\n\nurl &lt;-\n  \"https://en.wikipedia.org/wiki/List_of_highest-grossing_concert_tours\"\n\nNext, we’ll use the polite package to create a ‘bag of words’ (bow) representation of the URL. This step helps us make a polite request to the web server for the page’s content:\n\nurl_bow &lt;- polite::bow(url)\nurl_bow\n\n&lt;polite session&gt; https://en.wikipedia.org/wiki/List_of_highest-grossing_concert_tours\n    User-agent: polite R package\n    robots.txt: 456 rules are defined for 33 bots\n   Crawl delay: 5 sec\n  The path is scrapable for this user-agent\n\n\nOnce we have our ‘bow,’ we can use it to scrape the web page. We’ll specifically target the tables with the class ‘wikitable’ on the page:\n\nind_html &lt;-\n  polite::scrape(url_bow) %&gt;%  # scrape web page\n  rvest::html_nodes(\"table.wikitable\") %&gt;% # pull out specific table\n  rvest::html_table(fill = TRUE) \n\nFinally, we’ll clean up the extracted table (the second table on the page, Top 20 highest-grossing tours of all time) by storing it in the ind_tab variable and ensuring that column names are in a consistent format:\n\nind_tab &lt;- \n  ind_html[[2]] %&gt;% \n  clean_names()\n\nThis code segment efficiently fetches and prepares the data we need from the Wikipedia page. Our next step is to clean it for analysis. In this code snippet, we’ll perform some essential data cleaning tasks to make our dataset ready for exploration: transforming the Adjusted Gross in 2022 Dollars, Actual Gross, and Average Gross columns into numeric variables.\n\nind_tab_clean &lt;-\n  ind_tab %&gt;%\n  dplyr::mutate(across(\n    c(adjusted_gross_in_2022_dollars,\n      actual_gross,\n      averagegross),\n    ~ as.numeric(str_replace_all(.x, \"[$,]\", \"\"))\n  ))\n\nWe want to add Taylor’s data\n\nind_tab_tay &lt;-\n  ind_tab_clean %&gt;% \n  add_row(artist = \"Taylor Swift\",\n          tour_title = \"The Eras Tour (Expected)\",\n          year_s = \"2023-2024\",\n          shows = 146,\n          adjusted_gross_in_2022_dollars = 1400000000)\n\nNow that our data is clean and ready, let’s visualize the highest-grossing concert tours of all time (as of 2023) using a bar chart. We’ll use the ggplot2 package\n\nind_tab_tay %&gt;%\n  mutate(color = case_when(artist == \"Taylor Swift\" ~ \"#C2D9D9\",\n                          .default = \"#122B2B\")) %&gt;% \n  ggplot(aes(\n    x = forcats::fct_reorder(tour_title, adjusted_gross_in_2022_dollars),\n    y = adjusted_gross_in_2022_dollars\n  )) +\n  geom_col(aes(fill = color),\n           color = \"#122B2B\",\n           width= .9) +\n  scale_fill_identity() +\n  labs(title = \"Highest-grossing tours of all time\",\n       subtitle = \"(as of 2023)\") +\n  theme(\n    text = element_text(size = 9,\n                        family = \"open-sans\"),\n    title = element_text(size = 16,\n                              face = \"bold\",\n                              family = \"open-sans\"),\n    subtitle = element_text(size = 12,\n                                 family = \"open-sans\")\n  ) +\n  geom_text(aes(y = 12000000, label = tour_title),\n  family = \"open-sans\",\n  hjust = 0,\n  vjust = 0.5,\n  size = 3,\n  color = \"white\",\n  fontface = \"bold\") +\n    geom_text(aes(y = 12000000, label = ifelse(artist == \"Taylor Swift\", tour_title, \"\")),\n  family = \"open-sans\",\n  hjust = 0,\n  vjust = 0.5,\n  size = 3,\n  color = \"black\",\n  fontface = \"bold\") +\n  geom_text(aes(\n    label = scales::dollar(\n      adjusted_gross_in_2022_dollars,\n      accuracy = 1,\n      scale = 1e-6,\n      suffix = \"M\"\n    )\n  ),\n  family = \"open-sans\",\n  hjust = -0.1,\n  vjust = 0.5,\n  size = 3) +\n  coord_flip() +\n  scale_y_continuous(limits = c(0, 1500000000)) +\n  theme_void()"
  }
]