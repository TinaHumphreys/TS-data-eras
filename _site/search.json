[
  {
    "objectID": "notebooks/highest-grossing-tours-r.html",
    "href": "notebooks/highest-grossing-tours-r.html",
    "title": "",
    "section": "",
    "text": "See R code\n\n\n\n\n\n\n\nHighest-grossing tours of all time visualization\n\n\n\nLet’s get started by loading the necessary R packages to clean, scrape, and visualize the data. These packages are the building blocks of our data scraping journey.\n\n# To clean data\nlibrary(tidyverse)\nlibrary(janitor)\n\n# To scrape data\nlibrary(rvest)\nlibrary(httr)\nlibrary(polite)\n\n# To visualize data\nlibrary(ggplot2)\nlibrary(showtext)\n\nfont_add_google(\"Abril Fatface\", \"abril-fatface\")\nfont_add_google(\"Lato\", \"lato\")\n\nshowtext::showtext_auto()\n\nNow that we have the necessary libraries loaded, it’s time to politely scrape data from Wikipedia and bring it into R. We’ll start by specifying the URL of the Wikipedia page we want to extract data from:\n\nurl &lt;-\n  \"https://en.wikipedia.org/wiki/List_of_highest-grossing_concert_tours\"\n\nNext, we’ll use the `polite’ package to create a ‘bag of words’ (bow) representation of the URL. This step helps us make a polite request to the web server for the page’s content:\n\nurl_bow &lt;- polite::bow(url)\nurl_bow\n\nOnce we have our ‘bow,’ we can use it to scrape the web page. We’ll specifically target the tables with the class ‘wikitable’ on the page:\n\nind_html &lt;-\n1  polite::scrape(url_bow) |&gt;\n2  rvest::html_nodes(\"table.wikitable\") |&gt;\n  rvest::html_table(fill = TRUE) \n\n\n1\n\nScrape the webpage\n\n2\n\nPull out the specific table\n\n\n\n\nFinally, we’ll clean up the extracted table (the second table on the page, Top 20 highest-grossing tours of all time) by storing it in the ind_tab variable and ensuring that column names are in a consistent format:\n\nind_tab &lt;- \n  ind_html[[2]] |&gt; \n  clean_names()\n\nThis code segment efficiently fetches and prepares the data we need from the Wikipedia page. Our next step is to clean it for analysis. In this code snippet, we’ll perform some essential data cleaning tasks to make our dataset ready for exploration: transforming the Adjusted Gross in 2022 Dollars, Actual Gross, and Average Gross columns into numeric variables.\n\nind_tab_clean &lt;-\n  ind_tab |&gt;\n  dplyr::mutate(across(\n    c(adjusted_gross_in_2022_dollars,\n      actual_gross,\n      averagegross),\n    ~ as.numeric(str_replace_all(.x, \"[$,]\", \"\"))\n  ))\n\nWe want to add Taylor’s data:\n\nind_tab_tay &lt;-\n  ind_tab_clean |&gt; \n  add_row(artist = \"Taylor Swift\",\n          tour_title = \"The Eras Tour (Expected)\",\n          year_s = \"2023-2024\",\n          shows = 146,\n          adjusted_gross_in_2022_dollars = 1400000000,\n          .before = 1)\n\nNow that our data is clean and ready, let’s visualize the highest-grossing concert tours of all time (as of 2023) using a bar chart. We’ll use the ggplot2 package.\n\nind_tab_tay |&gt;\n  slice(1:10) |&gt; \n  mutate(color = case_when(artist == \"Taylor Swift\" ~ \"#D3ABD0\",\n                           .default = \"#903345\")) |&gt;\n  ggplot(aes(x = forcats::fct_reorder(tour_title,\n                             adjusted_gross_in_2022_dollars),\n             y = adjusted_gross_in_2022_dollars)) +\n  geom_col(aes(fill = color),\n           color = \"black\",\n           width = .9) +\n  scale_fill_identity() +\n  labs(title = \"Highest-grossing tours of all time\",\n       subtitle = \"(as of 2023)\") +\n  theme(text = element_text(size = 9,\n                            family = \"lato\"),\n        title = element_text(size = 16,\n                             family = \"abril-fatface\")) +\n  geom_text(aes(y = 12000000, label = tour_title),\n            family = \"lato\",\n            hjust = 0,\n            vjust = 0.5,\n            size = 3,\n            color = \"white\",\n            fontface = \"bold\") +\n  geom_text(aes(y = 12000000,\n                label = ifelse(artist == \"Taylor Swift\", tour_title, \"\")),\n            family = \"lato\",\n            hjust = 0,\n            vjust = 0.5,\n            size = 3,\n            color = \"black\",\n            fontface = \"bold\") +\n  geom_text(aes(\n      label = scales::dollar(\n        adjusted_gross_in_2022_dollars,\n        accuracy = 1,\n        scale = 1e-6,\n        suffix = \"M\")),\n      family = \"lato\",\n      hjust = -0.1,\n      vjust = 0.5,\n      size = 3) +\n  coord_flip() +\n  scale_y_continuous(limits = c(0, 1500000000)) +\n  scale_x_discrete(labels = ind_tab_tay |&gt; slice(1:10) |&gt; arrange(adjusted_gross_in_2022_dollars) |&gt; pull(artist)) +\n  theme(panel.background = element_blank(),\n        axis.ticks.x = element_blank(),\n        axis.text.x = element_blank(),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank())\n\n\nlibrary(ggpattern)\n\ntaylor &lt;- here::here(\"notebooks\", \"tours-images\", \"taylor.jpg\")\nu2 &lt;- here::here(\"notebooks\", \"tours-images\", \"u2.jpg\")\nelton &lt;- here::here(\"notebooks\", \"tours-images\", \"elton.jpg\")\ned &lt;- here::here(\"notebooks\", \"tours-images\", \"ed.jpg\")\nstones &lt;- here::here(\"notebooks\", \"tours-images\", \"stones.jpg\")\ngnr &lt;- here::here(\"notebooks\", \"tours-images\", \"gnr.jpg\")\ncoldplay &lt;- here::here(\"notebooks\", \"tours-images\", \"coldplay.jpg\")\nharry &lt;- here::here(\"notebooks\", \"tours-images\", \"harry.jpg\")\nbeyonce &lt;- here::here(\"notebooks\", \"tours-images\", \"beyonce.jpg\")\n\nind_tab_tay |&gt;\n  slice(1:10) |&gt; \n  ggplot(aes(x = forcats::fct_reorder(tour_title,\n                             adjusted_gross_in_2022_dollars),\n             y = adjusted_gross_in_2022_dollars)) +\n  geom_bar_pattern(aes(x = forcats::fct_reorder(tour_title,\n                             adjusted_gross_in_2022_dollars),\n                       y = adjusted_gross_in_2022_dollars,\n                   pattern_filename = as.factor(artist)),\n                   alpha = 0,\n                   pattern = \"image\",\n                   pattern_type = \"squish\",\n                   stat = \"identity\") +\n  scale_pattern_filename_manual(\n    values = c(`Taylor Swift` = taylor, \n               `Elton John` = elton, \n               `Ed Sheeran` = ed,\n               `U2` = u2,\n               `Coldplay` = coldplay,\n               `Harry Styles` = harry,\n               `Guns N' Roses` = gnr,\n               `Beyonce` = beyonce,\n               `The Rolling Stones` = stones)) +\n  scale_fill_identity() +\n  labs(title = \"Highest-grossing tours of all time\",\n       subtitle = \"(as of 2023)\") +\n  theme(text = element_text(size = 9,\n                            family = \"lato\"),\n        title = element_text(size = 16,\n                             family = \"abril-fatface\")) +\n  geom_text(aes(y = 12000000, label = tour_title),\n            family = \"lato\",\n            hjust = 0,\n            vjust = 0.5,\n            size = 3,\n            color = \"white\",\n            fontface = \"bold\") +\n  geom_text(aes(y = 12000000,\n                label = ifelse(artist == \"Taylor Swift\", tour_title, \"\")),\n            family = \"lato\",\n            hjust = 0,\n            vjust = 0.5,\n            size = 3,\n            color = \"black\",\n            fontface = \"bold\") +\n  geom_text(aes(\n      label = scales::dollar(\n        adjusted_gross_in_2022_dollars,\n        accuracy = 1,\n        scale = 1e-6,\n        suffix = \"M\")),\n      family = \"lato\",\n      hjust = -0.1,\n      vjust = 0.5,\n      size = 3) +\n  coord_flip() +\n  scale_y_continuous(limits = c(0, 1500000000)) +\n  scale_x_discrete(labels = ind_tab_tay |&gt; slice(1:10) |&gt; arrange(adjusted_gross_in_2022_dollars) |&gt; pull(artist)) +\n  theme(panel.background = element_blank(),\n        axis.ticks.x = element_blank(),\n        axis.text.x = element_blank(),\n        axis.title.x = element_blank(),\n        axis.title.y = element_blank())"
  },
  {
    "objectID": "notebooks/highest-gross-tours-decade-r.html",
    "href": "notebooks/highest-gross-tours-decade-r.html",
    "title": "",
    "section": "",
    "text": "See R code\n\n\n\n\n\n\n\nTip\n\n\n\n\ncombine_data &lt;- function(ind_html_list) {\n  # Initialize an empty tibble\n  combined_data &lt;- tibble()\n  \n  # Loop through the ind_html_list and append each element to the combined_data\n  for (i in 4:8) {\n    extracted_data &lt;- ind_html_list[[i]] |&gt; clean_names()\n    combined_data &lt;- bind_rows(combined_data, extracted_data)\n  }\n  \n  return(combined_data)\n}\n\nannual_hi_gross_tours &lt;- combine_data(ind_html)\n\n\ntours_by_decade &lt;-\n  annual_hi_gross_tours |&gt;\n  dplyr::mutate(across(\n    c(adjusted_gross_in_2022_dollar,\n      averagegross,\n      actual_gross),\n    ~ as.numeric(str_replace_all(.x, \"[$,]\", \"\"))\n  )) |&gt;\n  mutate(\n    start_year = str_sub(year_s, start = 1, end = 4),\n    year = lubridate::ymd(start_year, truncated = 2L)\n  ) |&gt;\n  mutate(\n    decade = paste0(str_sub(\n      as.factor(floor_date(year, years(10))), start = 1, end = 4\n    ), \"s\"),\n    `Adjusted Gross` = -adjusted_gross_in_2022_dollar,\n    `Average Gross` = averagegross) |&gt;\n  pivot_longer(cols = c(`Adjusted Gross`, `Average Gross`)) |&gt;\n  mutate(title = case_when(str_detect(tour_title, artist) ~ tour_title,\n                           .default = paste0(artist, \" \", tour_title)))\n\n\nggplot(tours_by_decade) +\n  geom_col(aes(value, \n               fct_reorder(tour_title, year, .desc = TRUE), \n               fill = decade)) +\n  geom_text(data = tours_by_decade |&gt; filter(name == \"Average Gross\"),\n            aes(x = 0, tour_title, label = title),\n            hjust = 0.5,\n            nudge_x = -5000000,\n            family = \"lato\",\n            size = 3.5) +\n  facet_grid2(rows = vars(decade),\n              cols = vars(toupper(name)),\n              scales = \"free\",\n              space = \"free_y\",\n              strip = strip_split(\n                c(\"top\", \"top\"),\n                text_x = elem_list_text(color = c(\"#903345\", \"grey60\")),\n                by_layer_x = TRUE)) +\n  scale_x_facet(PANEL == 1, limits = c(-900000000, 0), labels = abs) +\n  scale_x_facet(PANEL == 2, limits = c(0, 14000000)) +\n  labs(title = \"Top 10 highest-grossing tours by decade\",\n       caption = \"Source: Wikipedia · † Indicates the tour ongoing · Graphic: Inspired by Georgios Karamanis\") +\n  theme_minimal() +\n  coord_cartesian(clip = \"off\") +\n  theme(\n    panel.spacing.x=unit(4, \"lines\"),\n    legend.position = \"none\",\n    plot.background = element_rect(fill = \"white\", color = NA),\n    axis.text.y = element_blank(),\n    axis.title = element_blank(),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    strip.text = element_text(size = 12, face = \"bold\"),\n    plot.title = element_text(face = \"bold\",\n                              size = 20,\n                              family = \"abril-fatface\"),\n    text = element_text(size = 9,\n                            family = \"lato\")\n  ) +\n  scale_fill_manual(values = c(\"1980s\" = \"#434961\", \n                               \"1990s\" = \"#421E18\", \n                               \"2000s\" = \"#EBBED3\", \n                               \"2010s\" = \"#AA9EB6\", \n                               \"2020s\" = \"#A91E47\"))\n\n# ggsave(\n#   file = \"images/highest-grossing-tour-decade.png\",\n#   width = 4,\n#   height = 8,\n#   dpi = 300\n# )\n\n\ndecades &lt;- c(\"1980s\", \"1990s\", \"2000s\", \"2010s\")\n\ndecade_plots &lt;- function(individual_decade){\n  \n  decade_dat &lt;- tours_by_decade |&gt; \n    filter(decade == individual_decade)\n  \n  p &lt;-\n    ggplot(decade_dat) +\n    geom_col(aes(value,\n                 fct_reorder(tour_title, year, .desc = TRUE),\n                 fill = decade)) +\n    geom_text(\n      data = decade_dat |&gt; filter(name == \"Average Gross\"),\n      aes(x = 0, tour_title, label = title),\n      hjust = 0.5,\n      nudge_x = -12500000,\n      family = \"lato\",\n      size = 3.5\n    ) +\n    facet_grid2(\n      rows = vars(decade),\n      cols = vars(toupper(name)),\n      scales = \"free\",\n      space = \"free_y\",\n      strip = strip_split(\n        c(\"top\", \"top\"),\n        text_x = elem_list_text(color = c(\"#903345\", \"grey60\")),\n        by_layer_x = TRUE\n      )\n    ) +\n    scale_x_facet(PANEL == 1, limits = c(-3000000000, 0), labels = abs) +\n    scale_x_facet(PANEL == 2, limits = c(0, 14000000)) +\n    theme_minimal() +\n    coord_cartesian(clip = \"off\") +\n    theme(\n      panel.spacing.x = unit(15, \"lines\"),\n      legend.position = \"none\",\n      plot.background = element_rect(fill = \"white\", color = NA),\n      axis.text.y = element_blank(),\n      axis.title = element_blank(),\n      panel.grid.major = element_blank(),\n      panel.grid.minor = element_blank(),\n      strip.text = element_text(size = 12, face = \"bold\"),\n      plot.title = element_text(\n        face = \"bold\",\n        size = 20,\n        family = \"abril-fatface\"\n      ),\n      text = element_text(size = 9,\n                          family = \"lato\")\n    ) +\n    scale_fill_manual(\n      values = c(\n        \"1980s\" = \"#434961\",\n        \"1990s\" = \"#421E18\",\n        \"2000s\" = \"#EBBED3\",\n        \"2010s\" = \"#AA9EB6\"\n      )\n    )\n  \n  save(p,\n       file = paste0(\"images/highest-grossing-tour-\", individual_decade, \".rdata\"))\n  \n}\n\npurrr::map(.f = decade_plots, .x = decades)\n\n\n# https://stackoverflow.com/questions/39584669/r-dotted-predicted-above-solid-bars-in-bar-graph\n\ntour_2020_data &lt;- \n  tours_by_decade |&gt; \n  filter(decade == \"2020s\") |&gt;\n  mutate(group = \"b\") |&gt; \n  add_row(adjusted_gross_in_2022_dollar = 2200000000, \n          artist = \"Taylor Swift\",\n          shows = 146,\n          start_year = \"2023\",\n          year = as.Date(\"2023-01-01\"),\n          name = \"Adjusted Gross\",\n          value = -2200000000,\n          title = \"Taylor Swift The Eras Tour †\",\n          tour_title = \"The Eras Tour †\",\n          year_s = \"2023\",\n          averagegross = 13928571,\n          decade = \"2020s\",\n          group = \"a\")\n\np_2020s &lt;-\n  tour_2020_data |&gt;\n  ggplot() +\n    geom_col(aes(value,\n                 fct_reorder(tour_title, year, .desc = TRUE),\n                 fill = group)) +\n    geom_text(\n      data = tour_2020_data |&gt; filter(name == \"Average Gross\"),\n      aes(x = 0, tour_title, label = title),\n      hjust = 0.5,\n      nudge_x = -12500000,\n      family = \"lato\",\n      size = 3.5\n    ) +\n    facet_grid2(\n      rows = vars(decade),\n      cols = vars(toupper(name)),\n      scales = \"free\",\n      space = \"free_y\",\n      strip = strip_split(\n        c(\"top\", \"top\"),\n        text_x = elem_list_text(color = c(\"#903345\", \"grey60\")),\n        by_layer_x = TRUE\n      )\n    ) +\n    scale_x_facet(PANEL == 1, limits = c(-3000000000, 0), labels = abs) +\n    scale_x_facet(PANEL == 2, limits = c(0, 14000000)) +\n    theme_minimal() +\n    coord_cartesian(clip = \"off\") +\n    theme(\n      panel.spacing.x = unit(15, \"lines\"),\n      legend.position = \"none\",\n      plot.background = element_rect(fill = \"white\", color = NA),\n      axis.text.y = element_blank(),\n      axis.title = element_blank(),\n      panel.grid.major = element_blank(),\n      panel.grid.minor = element_blank(),\n      strip.text = element_text(size = 12, face = \"bold\"),\n      plot.title = element_text(\n        face = \"bold\",\n        size = 20,\n        family = \"abril-fatface\"\n      ),\n      text = element_text(size = 9,\n                          family = \"lato\")\n    ) +\n    scale_fill_manual(\n      values = c(\"#29384D\", \"#A91E47\")\n      )\n\nsave(p_2020s, file = \"images/highest-grossing-tour-2020s.rdata\")"
  },
  {
    "objectID": "notebooks/get-songstats-data.html",
    "href": "notebooks/get-songstats-data.html",
    "title": "",
    "section": "",
    "text": "See R code\n\n\n\n\n\n\n\nTip\n\n\n\n\nlibrary(httr)\nlibrary(jsonlite)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(purrr)\nlibrary(readr)\nlibrary(glue)\n\nget_artist_data &lt;- function(artist_name, songstats_artist_id) {\n  url &lt;-\n    \"https://api.songstats.com/enterprise/v1/artists/historic_stats\"\n  \n  queryString &lt;- list(\n    source = \"all\",\n    songstats_artist_id = songstats_artist_id,\n    start_date = \"2020-01-01\"\n  )\n  \n  response &lt;- httr::VERB(\n    \"GET\",\n    url,\n    query = queryString,\n    add_headers(\n      \"Accept-Encoding\" = \"\",\n      \"apikey\" = Sys.getenv(\"SONGSTATS_TOKEN\")\n    ),\n    content_type(\"application/octet-stream\"),\n    accept(\"application/json\")\n  )\n  \n  artist_data &lt;- httr::content(response, \"text\")\n  \n  artist_tibble &lt;- artist_data |&gt;\n    jsonlite::fromJSON() |&gt;\n    purrr::map_if(is.data.frame, list) |&gt;\n    as.data.frame() |&gt;\n    tidyr::unnest_wider(stats.data) |&gt;\n    tidyr::unnest(history) |&gt;\n    dplyr::mutate(\n      time_frame = dplyr::case_when(date &lt; \"2022-11-01\" ~ \"before announcement\",\n                                    .default = \"after announcement\"),\n      artist = artist_name\n    )\n  \n  file_name &lt;- glue::glue(\"{artist_name}_tibble.Rds\")\n  readr::write_rds(artist_tibble, \"data/file_name\")\n  \n  return(artist_tibble)\n}\n\n# Create a list of artists and their IDs\nartists &lt;- list(\n  c(\"Paramore\", \"p5xm8h7b\"),\n  c(\"Beabadoobee\", \"n3k29evr\"),\n  c(\"Phoebe Bridgers\", \"9yhbd1el\"),\n  c(\"Girl In Red\", \"p71m4gr8\"),\n  c(\"MUNA\", \"fyxmowt5\"),\n  c(\"HAIM\", \"apuz50ix\"),\n  c(\"GAYLE\", \"q16uf7gk\"),\n  c(\"OWENN\", \"cztp0nug\"),\n  c(\"Gracie Abrams\", \"so4cd0bt\"),\n  c(\"Taylor Swift\", \"i5muw4xf\")\n)\n\nartist_data_list &lt;-\n  map(artists, ~ get_artist_data(.x[1], .x[2]))\n\ncombined_artist_data &lt;-\n  bind_rows(artist_data_list)\n\nwrite_rds(combined_artist_data, \"secret-data/combined_artist_data.rds\")"
  },
  {
    "objectID": "notebooks/annual-highest-grossing-tours-r.html",
    "href": "notebooks/annual-highest-grossing-tours-r.html",
    "title": "",
    "section": "",
    "text": "See R code\n\n\n\n\n\n\n\nTip\n\n\n\n\nannual_hi_gross_tours &lt;-\n  ind_html[[9]] |&gt;\n  clean_names()\n\n\nannual_hi_gross_tours_clean &lt;-\n  annual_hi_gross_tours |&gt;\n  dplyr::mutate(across(\n    c(adjusted_gross_in_2022_dollar,\n      actual_gross),\n    ~ as.numeric(str_replace_all(.x, \"[$,]\", \"\"))\n  ),\n  year = lubridate::ymd(year, truncated = 2L),\n  decade = as.factor(floor_date(year, years(10)))) |&gt; \n  add_row(artist = \"Taylor Swift\",\n          tour_title = \"The Eras Tour (Expected)\",\n          year = lubridate::date(\"2023-01-01\"),\n          shows = 146,\n          adjusted_gross_in_2022_dollar = 1400000000,\n          decade = \"2020-01-01\",\n          .before = 1)\n\n\nannual_hi_gross_tours_clean |&gt;\n  ggplot(aes(\n    x = year,\n    y = adjusted_gross_in_2022_dollar,\n    fill = decade\n  )) +\n  geom_bar(stat = \"identity\") +\n  geom_smooth(aes(group = decade)) +\n  scale_size(range = c(0, 4)) +\n  theme_minimal() +\n  theme(\n    text = element_text(size = 9,\n                        family = \"lato\"),\n    title = element_text(size = 16,\n                         family = \"abril-fatface\"),\n    panel.background = element_blank(),\n    axis.ticks.x = element_blank(),\n    axis.text.x = element_blank(),\n    axis.title.x = element_blank(),\n    axis.title.y = element_blank()) +\n  geom_text(aes(label = tour_title),\n            family = \"lato\",\n            vjust = -2.5,\n            angle = 45,\n            size = 2) +\n  labs(title = \"Annual highest-grossing tours\")\n\n\nannual_hi_gross_tours_clean |&gt;\n  ggplot(aes(\n    x = shows,\n    y = adjusted_gross_in_2022_dollar,\n    fill = decade\n  )) +\n  geom_point(alpha = 0.5,\n             shape = 21,\n             color = \"black\") +\n  scale_size(range = c(0, 4)) +\n  scale_fill_viridis(discrete = TRUE,\n                     guide = FALSE,\n                     option = \"A\") +\n  theme_minimal() +\n  theme(\n    legend.position = \"none\",\n    text = element_text(size = 9,\n                        family = \"lato\"),\n    title = element_text(size = 16,\n                         family = \"abril-fatface\"),\n    panel.background = element_blank(),\n    axis.ticks.x = element_blank(),\n    axis.title.x = element_blank(),\n    axis.title.y = element_blank()\n  ) +\n  labs(title = \"Number of shows vs. income\")"
  },
  {
    "objectID": "notebooks/opener-data.html",
    "href": "notebooks/opener-data.html",
    "title": "",
    "section": "",
    "text": "Attaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "notebooks/eras-tour-dates-and-venues.html",
    "href": "notebooks/eras-tour-dates-and-venues.html",
    "title": "",
    "section": "",
    "text": "See R code\n\n\n\n\n\n\n\nThe Eras Tour Dates and Venues\n\n\n\nLet’s get started by loading the necessary R packages to clean, scrape, and visualize the data. These packages are the building blocks of our data scraping journey.\n\n# To clean data\nlibrary(tidyverse)\nlibrary(janitor)\n\n# To scrape data\nlibrary(rvest)\nlibrary(httr)\nlibrary(polite)\n\n# To geocode data\nlibrary(tidygeocoder)\nlibrary(lubridate)\n\n# To visualize data\nlibrary(leaflet)\n\nNow that we have the needed libraries let’s politely scrape data from Wikipedia and bring it into R. We’ll start by specifying the URL of the Wikipedia page we want to extract data from:\n\nurl_map &lt;-\n  \"https://www.sportskeeda.com/pop-culture/taylor-swift-2023-the-eras-tour-ticket-cities-and-dates\"\n\nurl_map_bow &lt;- polite::bow(url_map)\nurl_map_bow\n\n&lt;polite session&gt; https://www.sportskeeda.com/pop-culture/taylor-swift-2023-the-eras-tour-ticket-cities-and-dates\n    User-agent: polite R package\n    robots.txt: 41 rules are defined for 4 bots\n   Crawl delay: 5 sec\n  The path is scrapable for this user-agent\n\n\nNow, let’s extract and clean up our table.\n\nmap_html &lt;-\n  polite::scrape(url_map_bow) |&gt;  # scrape web page\n  rvest::html_nodes(\"tbody\") |&gt; # pull out specific table\n  rvest::html_table(fill = TRUE) |&gt;\n  bind_rows() |&gt;\n  row_to_names(row_number = 1) |&gt; # set the first row to column headers\n  clean_names()\n\nNow we want to geocode the locations in our table. We have a number of cities and venues, but where exactly are they located on a map? We’ll use the geocode function from the tidygeocoder package. Given these, it will return the geolocation, latitude and longitude based a specified geocoding service. We’ll use osm for Open Street Map.\nAfter that, we’ll clean up our table a bit more. We’ll note how many shows happen at each location and indicate whether those shows have happened yet.\n\nmap_html_geocode &lt;-\n  map_html |&gt;\n  geocode(venue,\n          method = \"osm\",\n          lat = latitude ,\n          long = longitude)\n\n# A few geolocation appear incorrect. Let's correct them manually. \nmap_html_geo &lt;-\n  map_html_geocode |&gt;\n  mutate(\n    latitude = case_when(\n      venue == \"Empower Field at Mile Hi\" ~ 39.74359,\n      venue == \"Johan Cruyff Arena\" ~ 52.3143,\n      .default = latitude\n    ),\n    longitude = case_when(\n      venue == \"Empower Field at Mile Hi\" ~ -105.01968,\n      venue == \"Johan Cruyff Arena\" ~ 4.94187,\n      .default = longitude\n    )\n  ) |&gt;\n  mutate(\n    number_shows = n(),\n    .by = c(venue, city)) |&gt;\n  mutate(\n    date = case_when(\n      date == \"March 18 (6:30 PM)\" ~ \"March 18\",\n      date == \"March 18 (12 PM)\" ~ \"March 18\",\n      .default = date\n    ),\n    date =  lubridate::mdy(paste0(date, \" \", year))\n  ) |&gt; \n  mutate(\n    occurred = case_when(\n     date &lt; today() ~ \"Occurred\",\n      date &gt; today() ~ \"Not Occurred\",\n      .default = \"NA\"))\n\nNow let’s use Leaflet to map all these shows and their venues.\n\n# set up the colors for our map markers\npal &lt;- colorFactor(\n  palette = c(\"#823549\", \"#1D1F38\"),\n  domain = map_html_geo$occurred\n)\n\nleaflet(options = leafletOptions(zoomControl = FALSE)) |&gt;\n  addProviderTiles(\"Esri.WorldGrayCanvas\",\n                   options = (noWrap = TRUE)) |&gt;\n  setMaxBounds(\n    lng1 = 180,\n    lat1 = 90,\n    lng2 = -180,\n    lat2 = -90\n  ) |&gt; \n  addCircleMarkers(\n    data = map_html_geo,\n    color = ~pal(occurred),\n    label = paste(\n      \"Venue: \",\n      map_html_geo$venue,\n      \"&lt;br&gt;\",\n      \"City: \",\n      map_html_geo$city,\n      \"&lt;br&gt;\",\n      \"Number of Shows: \",\n      map_html_geo$number_shows\n    ) |&gt;\n      lapply(htmltools::HTML)\n  ) |&gt; \n  addLegend(\"bottomright\", pal = pal, values = map_html_geo$occurred,\n            title = \"Event Status\",\n            opacity = 1\n  )"
  },
  {
    "objectID": "notebooks/taylor-vs-countries-gdp.html",
    "href": "notebooks/taylor-vs-countries-gdp.html",
    "title": "",
    "section": "",
    "text": "# To clean data\nlibrary(tidyverse)\nlibrary(janitor)\n\n# To scrape data\nlibrary(rvest)\nlibrary(httr)\nlibrary(polite)\n\n# To visualize data\nlibrary(ggplot2)\nlibrary(showtext)\nlibrary(cowplot)\n\nfont_add_google(\"Abril Fatface\", \"abril-fatface\")\nfont_add_google(\"Lato\", \"lato\")\n\nshowtext::showtext_auto()\n\n\nlibrary(rnaturalearth)\n\nfiji &lt;- \n  ne_countries(scale = 10, returnclass = \"sf\", country = \"Fiji\") \n\np_Fiji &lt;-\n  ggplot(fiji) +\n  geom_sf(fill = \"#823549\",\n          color = \"black\") +\n  coord_sf(\n    crs = 3460, # https://epsg.io/3460\n    ) +\n  theme_void() +\n  labs(title = ind_tab |&gt; filter(country_territory == \"Fiji\") |&gt; pull(country_territory),\n       subtitle = scales::dollar(ind_tab |&gt; filter(country_territory == \"Fiji\") |&gt; pull(world_bank_14), scale=1e6)) +\n    theme(\n      plot.subtitle = element_text(size = 12,\n                                   family = \"lato\",\n                                   hjust = 0.5),\n      plot.title = element_text(hjust = 0.5),\n      title = element_text(size = 16,\n                           family = \"abril-fatface\")\n    )\n\ncountries &lt;- c(\"Kosovo\", \"Somalia\", \"Togo\", \"Bermuda\", \"Montenegro\", \"Barbados\", \"Eswatini\")\n\ncolors &lt;- c(\"#b9d2b5\", \"#f4cb8d\", \"#d1b2d2\", \"#b5e9f6\", \"#F9B2D0\", \"#CFCAC6\", \"#C8AE95\")\n  \ncountry_plots &lt;- function(country, fill){\n  country_data &lt;-\n    ne_countries(scale = 10, returnclass = \"sf\", country = country)\n\n  p &lt;- ggplot(country_data) +\n    geom_sf(fill = fill,\n            color = \"black\") +\n    coord_sf() +\n    theme_void() +\n    labs(\n      title = ind_tab |&gt; filter(country_territory == country) |&gt; pull(country_territory),\n      subtitle = scales::dollar(\n        ind_tab |&gt; filter(country_territory == country) |&gt; pull(world_bank_14),\n        scale = 1e6\n      )\n    ) +\n    theme(\n      plot.subtitle = element_text(size = 12,\n                                   family = \"lato\",\n                                   hjust = 0.5),\n      plot.title = element_text(hjust = 0.5),\n      title = element_text(size = 16,\n                           family = \"abril-fatface\")\n    )\n  \nplot_name &lt;- paste(\"p_\", country, sep = \"\")\n  assign(plot_name, p, envir = .GlobalEnv)\n\n}\n\npurrr::map2(.f = country_plots, .x = countries, .y = colors)\n\n# One specifically for Taylor Swift\n\np_blank &lt;-\n  ggplot() +\n  labs(title = \"Taylor Swift\",\n       subtitle = \"$6,300,000,000\") +\n  theme_void() +\n  theme(\n    plot.subtitle = element_text(size = 12,\n                                 family = \"lato\",\n                                 hjust = 0.5),\n    plot.title = element_text(hjust = 0.5),\n    title = element_text(size = 24,\n                         family = \"abril-fatface\",\n                         hjust = 1,\n                         color = \"#434961\"))\n\n\ngdp_plot &lt;-\n  plot_grid(p_Kosovo, p_Somalia, p_Togo, p_Bermuda, p_blank, p_Montenegro, p_Barbados, p_Fiji, p_Eswatini, align = \"v\" ) + \n  draw_image(\n    here::here(\"notebooks\", \"t_swift.jpg\"),\n    x = 0.4,\n    y = 0.35,\n    width = 0.2,\n    height = 0.2\n  )\n\nsave(gdp_plot, file = here::here(\"images\", \"gdp_plot.rdata\"))\n\n\nurl &lt;-\n  \"https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)\"\n\nurl_bow &lt;- polite::bow(url)\nurl_bow\n\nind_html &lt;-\n  polite::scrape(url_bow) |&gt;\n  rvest::html_nodes(\"table.wikitable\") |&gt;\n  rvest::html_table(fill = TRUE) \n\nind_tab &lt;- \n  ind_html[[1]] |&gt; \n  janitor::clean_names() |&gt; \n  slice(-1) |&gt; \n  dplyr::mutate(across(\n    c(imf_1_13,\n      world_bank_14,\n      united_nations_15),\n    ~ as.numeric(str_replace_all(.x, \"[$,]\", \"\"))\n  )) |&gt; \n  filter(world_bank_14 &lt; 10000 & world_bank_14 &gt; 4900) |&gt; \n  arrange(desc(world_bank_14))\nurl &lt;-\n  \"https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)\"\n\nurl_bow &lt;- polite::bow(url)\nurl_bow\n\nind_html &lt;-\n  polite::scrape(url_bow) |&gt;\n  rvest::html_nodes(\"table.wikitable\") |&gt;\n  rvest::html_table(fill = TRUE) \n\nind_tab &lt;- \n  ind_html[[1]] |&gt; \n  janitor::clean_names() |&gt; \n  slice(-1) |&gt; \n  dplyr::mutate(across(\n    c(imf_1_13,\n      world_bank_14,\n      united_nations_15),\n    ~ as.numeric(str_replace_all(.x, \"[$,]\", \"\"))\n  )) |&gt; \n  filter(world_bank_14 &lt; 10000 & world_bank_14 &gt; 4000) |&gt; \n  arrange(desc(world_bank_14))\n\ncountries &lt;- unique(ind_tab$country_territory)"
  },
  {
    "objectID": "r.html",
    "href": "r.html",
    "title": "Taylor Swift’s Tour in the Pantheon of Music",
    "section": "",
    "text": "[to be added]",
    "crumbs": [
      "Walk through the code",
      "🔵 See the code in R"
    ]
  },
  {
    "objectID": "py.html",
    "href": "py.html",
    "title": "Taylor Swift’s Tour in the Pantheon of Music",
    "section": "",
    "text": "[to be added]",
    "crumbs": [
      "Walk through the code",
      "🐍 See the code in Python"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Taylor Swift’s Tour in the Pantheon of Music",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula. Aliquam sit amet ipsum ut nisl gravida molestie. Morbi orci tortor, dapibus a dictum vitae, congue sit amet lorem. Praesent purus risus, auctor ac neque sed, interdum feugiat erat. Fusce gravida pellentesque lacus, eget sodales elit sodales vitae. Nunc porttitor pulvinar bibendum.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula. Aliquam sit amet ipsum ut nisl gravida molestie. Morbi orci tortor, dapibus a dictum vitae, congue sit amet lorem. Praesent purus risus, auctor ac neque sed, interdum feugiat erat. Fusce gravida pellentesque lacus, eget sodales elit sodales vitae. Nunc porttitor pulvinar bibendum.\nDates\nMarch '23 - Nov '24\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSet list\n44 songs\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula. Aliquam sit amet ipsum ut nisl gravida molestie. Morbi orci tortor, dapibus a dictum vitae, congue sit amet lorem. Praesent purus risus, auctor ac neque sed, interdum feugiat erat. Fusce gravida pellentesque lacus, eget sodales elit sodales vitae. Nunc porttitor pulvinar bibendum.\nNumber of shows\n146\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEstimated attendance\n10,512,000\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\nNumber of countries\n17\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNumber of cities\n50\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula.\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula."
  },
  {
    "objectID": "index.html#the-eras-tour",
    "href": "index.html#the-eras-tour",
    "title": "Taylor Swift’s Tour in the Pantheon of Music",
    "section": "The Eras Tour",
    "text": "The Eras Tour"
  },
  {
    "objectID": "index.html#openers",
    "href": "index.html#openers",
    "title": "Taylor Swift’s Tour in the Pantheon of Music",
    "section": "Openers",
    "text": "Openers\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "notebooks/swift-v-others-sankey-bump.html",
    "href": "notebooks/swift-v-others-sankey-bump.html",
    "title": "Taylor Swift vs Other Tours",
    "section": "",
    "text": "# data loading and manipulation\nlibrary(tidyverse)\n\n# data visualization  \nlibrary(ggplot2)\nlibrary(scales)\nlibrary(glue)\nlibrary(ggsankey) # get at https://github.com/davidsjoberg/ggsankey\nlibrary(ggtext)\nlibrary(colorspace)\nlibrary(ggh4x)\n\nBorrowing heavily from Georgios Karamanis’ #TidyTuesday post, where he shared an alluvial bump chart made with {ggsankey} with data from UNHCR, the UN Refugee Agency The heaviest lift came from {ggsankey}, the R Package for making beautiful sankey, alluvial and sankey bump plots in ggplot2\nFirst, we’re going to load our data, collected manually from Pollstar reporting over the last 20 years. Artist names need to be cleaned up, and we need to structure our dataset for the Sankey Bump plot.\n\nrank_concert_tours &lt;- read_csv(\"../data/rank_concert_tours.csv\") |&gt; \n  mutate(\n    artist = case_when(\n      artist == \"Tim McGraw/Faith Hill\"  ~ \"Tim Mcgraw et. al.\",\n      artist == \"Tim McGraw / Faith Hill\"  ~ \"Tim Mcgraw et. al.\",     \n      artist == \"Kenny Chesney & Tim Mcgraw\"  ~ \"Tim Mcgraw et. al.\",     \n      artist == \"Michael Jackson The Immortal World Tour By Cirque Du Soleil\"  ~ \"Michael Jackson\",\n      artist == \"Bruce Springsteen & The E Street Band\"  ~ \"Bruce Springsteen & the E Street Band\",\n      artist == \"Jay-Z / Beyoncé\"   ~ \"Beyoncé & Jay Z\",\n      artist == \"Beyoncé and Jay Z\" ~ \"Beyoncé & Jay Z\",\n      artist == \"Billy Joel/Elton John\"  ~ \"Billy Joel & Elton John\"  ,\n      artist == \"“Summer Sanitarium Tour”/Metallica\"  ~ \"Metallica\",\n      artist == \"'N Sync\"  ~ \"Nsync\",\n      .default = artist\n    )\n  )\n\nfor (YEAR in unique(rank_concert_tours$year)){\n  # print(as.character(YEAR))\n  \n  year_tbl &lt;- rank_concert_tours |&gt; \n    filter(year == YEAR)\n  \n  add_tbl &lt;- tibble(\n    year = YEAR,\n    artist = (rank_concert_tours$artist |&gt; unique())[!(rank_concert_tours$artist |&gt; unique() %in% year_tbl$artist)],\n    gross = 1\n  )\n  add_tbl$rank &lt;- 11:(nrow(add_tbl)+10)\n  \n  year_tbl &lt;- year_tbl |&gt; \n    bind_rows(\n      add_tbl\n    )\n  \n  rank_concert_tours &lt;- year_tbl |&gt; \n    bind_rows(\n      rank_concert_tours |&gt; \n        filter(year != YEAR)\n    )\n  \n}\n\nrank_concert_tours &lt;- tibble(rank_concert_tours) |&gt; \n  arrange(year, rank)\n\n# Set artist as factor, set levels\n# This helps the visualization\n\n# artist we want in front\nartist_levels &lt;- c(\n  \"Taylor Swift\",\n  \"Ed Sheeran\",\n  \"The Rolling Stones\",\n  \"Bruce Springsteen & the E Street Band\",\n  \"U2\",\n  \"Elton John\",\n  \"Bad Bunny\"\n)\nartist_levels = c(\n  artist_levels,\n  \n  # everyone else, sorted alphabeically. \n  (rank_concert_tours$artist |&gt; unique())[!(rank_concert_tours$artist |&gt; unique() %in% artist_levels)] |&gt; sort()\n)\n\nrank_concert_tours$artist &lt;- factor(\n  x = rank_concert_tours$artist,\n  levels = artist_levels\n)\n\nNow, let’s use ggplot, ggsankey to build this plot.\nThe placement of much of the annotations is optimized for the square image output.\n\n# set text and position of major artist and tour annotation. \nannot &lt;- tribble(\n  ~artist, ~x, ~y, ~total, ~note, ~size,\n  \"The Rolling Stones\",2003.5, 1100,1216000000,\"between 2013-2023\",4.9,\n  \"Bruce Springsteen & the E Street Band\",2010,1550,268300000,\"in 2016\",4.9,\n  \"U2\", 2013, 1850, 316000000,\"in 2017\",4.9,\n  \"Ed Sheeran\",2017,2200,768200000,\"between 2017-2019\",5,\n  \"Elton John\",2018.5,2500,334400000,\"in 2022\",4.8,\n  \"Bad Bunny\",2018.5,2700,373500000,\"in 2022\",4.8,\n  \"Taylor Swift\",2018.6, 3000, 2200000000,\"Projected\",5.5\n) |&gt; rowwise() |&gt; \n  mutate(\n    label = glue(\"**{artist}**&lt;br&gt;{scales::dollar(total)} {note}\")\n  )\nartist_levels &lt;- c(\n  \"Taylor Swift\",\n  \"Ed Sheeran\",\n  \"The Rolling Stones\",\n  \"Bruce Springsteen & the E Street Band\",\n  \"U2\",\n  \"Elton John\",\n  \"Bad Bunny\"\n)\nannot$artist &lt;- factor(\n  x = annot$artist,\n  levels = artist_levels\n)\n\nf1 &lt;- \"Lato\"\nf2 &lt;- \"Abril Fatface\"\n\n# exporting manually: \np &lt;- rank_concert_tours |&gt; \n  mutate(\n    fill = artist,\n    fill = ifelse(artist %in% annot$artist, artist, NA)\n  ) |&gt; \n  ggplot( ) +\n  # create Sankey bump plot\n  geom_sankey_bump(\n    aes(\n      x = year, \n      node = artist, \n      fill = fill,\n      value = gross,\n      color = after_scale(colorspace::lighten(fill, 0.4))\n    ), \n    linewidth = 0.3, \n    type = \"alluvial\", \n    space = 0, \n    alpha = 0.9\n  ) +\n  # Labels for top artists\n  ggtext::geom_richtext(\n    data = annot, \n    aes(\n      x = x, \n      y = y, \n      label = label, \n      color = artist,\n      size = size\n    ), \n    vjust = 0, \n    family = f1, \n    fill = NA, \n    label.color = NA) + \n  # More labels\n  annotate(\"text\", x = 2023.2, y = 900, label = \"Mid-Year\\nTotal\\nfor Other\\nArtists\", family = f1, hjust = 0, vjust = 1, color = \"grey30\") +\n  # Title and subtitle\n  annotate(\n    \"text\", x = 2000, y = 3500, \n    label = str_wrap(\"How does Taylor Swift's Eras Tour Compare to Others?\", indent = 0), \n    size = 8, family = f2, fontface = \"bold\", hjust = 0, color = \"#181716\") +\n  annotate(\"text\", x = 2000, y = 3370, label = str_wrap(\"This plot shows rankings and revenue from each year's top ten international music tours between 2000 and 2023. Other top tours & artists are highlighted. \", 50), \n           size = 5.5, family = f1, hjust = 0, vjust = 1, color = \"#393433\",\n           lineheight = .9) +\n  \n  # Scales, coord, theme\n  scale_x_continuous(\n    breaks = seq(2002, 2022, 2),\n    minor_breaks = NULL, \n    guide = \"axis_minor\") +\n  scale_y_continuous(\n    labels = unit_format(\n      prefix = \"$\",\n      unit = \"Billion\", \n      scale = 1e-3),\n    limits = c(0,3600),\n    breaks = c(1000,2000),\n    minor_breaks = NULL\n  ) +\n  scale_fill_manual(\n    values = c(\"#1EB3B3\", \"#0041CC\", \"#e17d17\", \"#A713CC\",\"#CE1126\", \"#877DB8\",\"#38C754\"), na.value = \"grey80\") +\n  scale_color_manual(\n    values = c(\"#1EB3B3\", \"#0041CC\", \"#e17d17\", \"#A713CC\",\"#CE1126\", \"#877DB8\",\"#38C754\"), na.value = \"grey80\") +\n  scale_size_continuous(range = c(4, 6)) +\n  coord_cartesian(clip = \"off\", expand = FALSE) +\n  labs(\n    caption = \"Source: Pollstar. Projection by CNN & QuestionPro\"\n  ) +\n  theme_minimal(\n    base_family = f1\n  ) +\n  theme(\n    legend.position = \"none\",\n    plot.background = element_rect(fill = \"#FFFFFE\", color = NA),\n    axis.title = element_blank(),\n    axis.text = element_text(size = 12, margin = margin(5, 0, 0, 0), family = f1, color = \"#393433\"),\n    # axis.ticks.x = element_line(color = \"grey70\"),\n    # ggh4x.axis.ticks.length.minor = rel(1),\n    plot.margin = margin(20, 75, 30, 35),\n    plot.caption = element_text(margin = margin(10, 0, 0, 0))\n  )\n\np\n\nggsave(\n  filename = \"../images/tswift-v-others-sankey-sqr.png\",\n  plot = p,\n  device = png,\n  path = NULL,\n  scale = 1,\n  width = 10,\n  height = 10,\n  units = \"in\",\n  dpi = 300,\n  limitsize = TRUE,\n  bg = NULL\n)\n\nRectangle Version, for blog post.\n\n# set text and position of major artist and tour annotation. \nannot &lt;- tribble(\n  ~artist, ~x, ~y, ~total, ~note, ~size,\n  \"The Rolling Stones\",2004.5, 1100,1216000000,\"between 2013-2023\",5,\n  \"Bruce Springsteen & the E Street Band\",2012,1550,268300000,\"in 2016\",4.9,\n  \"U2\", 2015, 1900, 316000000,\"in 2017\",4.9,\n  \"Ed Sheeran\",2017,2200,768200000,\"between 2017-2019\",5.1,\n  \"Elton John\",2020,2550,334400000,\"in 2022\",4.8,\n  \"Bad Bunny\",2020,2800,373500000,\"in 2022\",4.8,\n  \"Taylor Swift\",2020.5, 3150, 2200000000,\"Projected\",5.5\n) |&gt; rowwise() |&gt; \n  mutate(\n    label = glue(\"**{artist}**&lt;br&gt;{scales::dollar(total)} {note}\")\n  )\n\nf1 &lt;- \"Lato\"\nf2 &lt;- \"Abril Fatface\"\n\n# exporting manually: \np &lt;- rank_concert_tours |&gt; \n  ggplot( ) +\n  # create Sankey bump plot\n  geom_sankey_bump(\n    aes(\n      x = year, \n      node = artist, \n      fill = ifelse(artist %in% annot$artist, artist, NA),\n      value = gross,\n      color = after_scale(colorspace::lighten(fill, 0.4))\n    ), \n    linewidth = 0.3, \n    type = \"alluvial\", \n    space = 0, \n    alpha = 0.9\n  ) +\n  # Labels for top artists\n  ggtext::geom_richtext(\n    data = annot, \n    aes(\n      x = x, \n      y = y, \n      label = label, \n      color = artist,\n      size = size\n    ), \n    vjust = 0, \n    family = f1, \n    fill = NA, \n    label.color = NA) + \n  # More labels\n  annotate(\"text\", x = 2023.2, y = 900, label = \"Mid-Year\\nTotal\\nfor Other\\nArtists\", family = f1, hjust = 0, vjust = 1, color = \"grey30\") +\n  # Title and subtitle\n  annotate(\n    \"text\", x = 2000, y = 3500, \n    label = str_wrap(\"How does Taylor Swift's Eras Tour Compare to Others?\", indent = 0), \n    size = 8, family = f2, fontface = \"bold\", hjust = 0, color = \"#181716\") +\n  annotate(\"text\", x = 2000, y = 3370, label = str_wrap(\"This plot shows rankings and revenue from each year's top ten international music tours between 2000 and 2023. Other top tours & artists are highlighted. \", 66), \n           size = 5.5, family = f1, hjust = 0, vjust = 1, color = \"#393433\",\n           lineheight = .9) +\n  \n  # Scales, coord, theme\n  scale_x_continuous(\n    breaks = seq(2002, 2022, 2),\n    minor_breaks = NULL, \n    guide = \"axis_minor\") +\n  scale_y_continuous(\n    labels = unit_format(\n      prefix = \"$\",\n      unit = \"Billion\", \n      scale = 1e-3),\n    limits = c(0,3600),\n    breaks = c(1000,2000),\n    minor_breaks = NULL\n  ) +\n  scale_fill_manual(\n    values = c(\"#1EB3B3\", \"#0041CC\", \"#e17d17\", \"#A713CC\",\"#CE1126\", \"#877DB8\",\"#38C754\"), na.value = \"grey80\") +\n  scale_color_manual(\n    values = c(\"#1EB3B3\", \"#0041CC\", \"#e17d17\", \"#A713CC\",\"#CE1126\", \"#877DB8\",\"#38C754\"), na.value = \"grey80\") +\n  scale_size_continuous(range = c(4, 6)) +\n  coord_cartesian(clip = \"off\", expand = FALSE) +\n  labs(\n    caption = \"Source: Pollstar. Projection by CNN & QuestionPro\"\n  ) +\n  theme_minimal(\n    base_family = f1\n  ) +\n  theme(\n    legend.position = \"none\",\n    plot.background = element_rect(fill = \"#FFFFFE\", color = NA),\n    axis.title = element_blank(),\n    axis.text = element_text(size = 12, margin = margin(5, 0, 0, 0), family = f1, color = \"#393433\"),\n    # axis.ticks.x = element_line(color = \"grey70\"),\n    # ggh4x.axis.ticks.length.minor = rel(1),\n    plot.margin = margin(20, 75, 30, 35),\n    plot.caption = element_text(margin = margin(10, 500, 0, 0))\n  )\n\n# p\n\nggsave(\n  filename = \"../images/tswift-v-others-sankey-rect.png\",\n  plot = p,\n  device = jpeg,\n  path = NULL,\n  scale = 1,\n  width = 14,\n  height = 8,\n  units = \"in\",\n  dpi = 300,\n  limitsize = TRUE,\n  bg = NULL\n)"
  },
  {
    "objectID": "notebooks/most-streamed-artists.html",
    "href": "notebooks/most-streamed-artists.html",
    "title": "",
    "section": "",
    "text": "# To clean data\nlibrary(tidyverse)\nlibrary(janitor)\n\n# To scrape data\nlibrary(rvest)\nlibrary(httr)\nlibrary(polite)\n\n\nstreams_url &lt;-\n  \"https://en.wikipedia.org/wiki/List_of_most-streamed_artists_on_Spotify\"\n\nstreams_url_bow &lt;- polite::bow(streams_url)\n\nind_html &lt;-\n1  polite::scrape(streams_url_bow) |&gt;\n2  rvest::html_nodes(\"table.wikitable\") |&gt;\n  rvest::html_table(fill = TRUE)\n\n\n1\n\nScrape the webpage\n\n2\n\nPull out anything that is a wikitable\n\n\n\n\n\ntop_listeners_tab &lt;- \n  ind_html[[4]] |&gt; \n  clean_names()\n\nmost_followed_tab &lt;- \n  ind_html[[5]] |&gt; \n  clean_names()\n\nspotify_data &lt;-\n  left_join(top_listeners_tab, most_followed_tab, join_by(artist == artist_68)) |&gt; \n  rename(monthly_listeners_millions_rank = rank.x,\n         followers_millions_rank = rank.y)"
  },
  {
    "objectID": "notebooks/taylor-music.html",
    "href": "notebooks/taylor-music.html",
    "title": "",
    "section": "",
    "text": "Attaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n`summarise()` has grouped output by 'month'. You can override using the\n`.groups` argument."
  },
  {
    "objectID": "notebooks/taylor-live-performances.html",
    "href": "notebooks/taylor-live-performances.html",
    "title": "",
    "section": "",
    "text": "# To clean data\nlibrary(tidyverse)\nlibrary(janitor)\n\n# To scrape data\nlibrary(rvest)\nlibrary(httr)\nlibrary(polite)\n\n# To visualize data\nlibrary(ggplot2)\nlibrary(showtext)\nlibrary(treemapify)\n\nfont_add_google(\"Abril Fatface\", \"abril-fatface\")\nfont_add_google(\"Lato\", \"lato\")\n\nshowtext::showtext_auto()\n\n\nurl &lt;-\n  \"https://en.wikipedia.org/wiki/List_of_Taylor_Swift_live_performances\"\n\nurl_bow &lt;- polite::bow(url)\nurl_bow\n\nind_html &lt;-\n  polite::scrape(url_bow) |&gt;\n  rvest::html_nodes(\"table.wikitable\") |&gt;\n  rvest::html_table(fill = TRUE) \n\nind_tab &lt;- \n  ind_html[[1]] |&gt; \n  janitor::clean_names() |&gt; \n  dplyr::mutate(across(\n    c(adjusted_gross_in_2023_dollar,\n      gross,\n      attendance),\n    ~ as.numeric(str_replace_all(.x, \"[$,]\", \"\"))\n  )) |&gt; \n  dplyr::mutate(attendance = case_when(title == \"The Eras Tour\" ~ 10512000,\n                                       .default = attendance),\n                gross = case_when(title == \"The Eras Tour\" ~ 2200000000,\n                                       .default = gross),\n                adjusted_gross_in_2023_dollar = case_when(title == \"The Eras Tour\" ~ 2200000000,\n                                       .default = adjusted_gross_in_2023_dollar),\n                label = paste0(title, \"&lt;br&gt;&lt;span style='font-size:30pt'&gt;\", scales::dollar(adjusted_gross_in_2023_dollar), \"&lt;/span&gt;\"),\n                image = case_when(title == \"The Eras Tour\" ~ \"&lt;img src='notebooks/logo-images/eras.png'&gt;\",\n                                  title == \"Fearless Tour\" ~ \"&lt;img src='notebooks/logo-images/fearless.png' style='width:30%'&gt;\",\n                                  title == \"The 1989 World Tour\" ~ \"&lt;img src='notebooks/logo-images/1989.png'&gt;\",\n                                  title == \"Reputation Stadium Tour\" ~ \"&lt;img src='notebooks/logo-images/reputation.png'&gt;\",\n                                  title == \"Speak Now World Tour\" ~ \"&lt;img src='notebooks/logo-images/speak_now.jpg'&gt;\",\n                                  title == \"The Red Tour\" ~ \"&lt;img src='notebooks/logo-images/red.jpg'&gt;\")) %&gt;%\n  mutate(image = paste0(image, \"&lt;br&gt;&lt;span style='font-size:30pt'&gt;\", scales::dollar(adjusted_gross_in_2023_dollar), \"&lt;/span&gt;\")) %&gt;% \n  mutate(adjusted_gross_in_2023_dollar2 = case_when(title == \"Fearless Tour\" ~ adjusted_gross_in_2023_dollar * 1.5,\n                                                   .default = adjusted_gross_in_2023_dollar))\n\ntreemap &lt;-\n  treemapify(ind_tab, area = \"adjusted_gross_in_2023_dollar\")\n\ntreemap &lt;-\n  left_join(ind_tab, treemap |&gt; select(title, ymax:xmax))\n\ntotal &lt;- sum(ind_tab$adjusted_gross_in_2023_dollar)\n\n# https://github.com/wilkox/treemapify/issues/37\ntreemap |&gt;\n  ggplot(\n    aes(\n      area = adjusted_gross_in_2023_dollar2,\n      fill = title,\n      label = paste(title, scales::dollar(adjusted_gross_in_2023_dollar), sep = \"\\n\")\n    )\n  ) +\n  geom_treemap() +\n  geom_treemap_text(\n    colour = \"#1D1E3C\",\n    place = \"center\",\n    grow = TRUE,\n    reflow = FALSE,\n    family = \"abril-fatface\"\n  ) +\n  # ggfittext::geom_fit_text(\n  #   family = \"abril-fatface\",\n  #   color = \"white\",\n  #   place = \"center\",\n  #   grow = FALSE,\n  #   rich = TRUE,\n  #   contrast = TRUE\n  # ) +\n  labs(title = scales::dollar(total)) +\n  theme_void() +\n  theme(\n    legend.position = \"none\",\n    plot.title = element_text(\n      size = 70,\n      family = \"abril-fatface\",\n      hjust = 0.5,\n      color = \"#1D1E3C\"\n    )\n  ) +\n  scale_fill_manual(values = c(\"#b9d2b5\",\n                               \"#f4cb8d\",\n                               \"#b5e9f6\",\n                               \"#d1b2d2\",\n                               \"#CFCAC6\",\n                               \"#C8AE95\")) -&gt; taylor_treemap\n\nsave(taylor_treemap, file = \"images/taylor_treemap.rdata\")"
  },
  {
    "objectID": "notebooks/cost-per-ticket.html",
    "href": "notebooks/cost-per-ticket.html",
    "title": "",
    "section": "",
    "text": "url2 &lt;-\n  \"https://en.wikipedia.org/wiki/List_of_most-attended_concert_tours\"\n\nurl_bow2 &lt;- polite::bow(url2)\nurl_bow2\n\nind_html2 &lt;-\n  polite::scrape(url_bow2) |&gt;  # scrape web page\n  rvest::html_nodes(\"table.wikitable\") |&gt; # pull out specific table\n  rvest::html_table(fill = TRUE)\n\nind_tab2 &lt;-\n  ind_html2[[2]] |&gt;\n  janitor::clean_names() |&gt;\n  dplyr::mutate(tickets_sold = as.numeric(str_replace(tickets_sold, \" million.*\", \"\")) * 1e6)\n\ntours_by_decade2 &lt;-\n  tours_by_decade |&gt;\n  dplyr::mutate(\n    tour_title = case_when(\n      tour_title == \"Music of the Spheres World Tour †\" ~ \"Music of the Spheres World Tour\",\n      tour_title == \"The Garth Brooks World Tour\" ~ \"The Garth Brooks World Tour (1996–1998)\",\n      tour_title == \"Steel Wheels Tour\" ~ \"Steel Wheels/Urban Jungle Tour\",\n      .default = tour_title\n    )\n  )\n\ncost_per &lt;-\n  left_join(ind_tab2, tours_by_decade2, join_by(tour_title))\n\n\ncost_per |&gt;\n  mutate(cost_per = adjusted_gross_in_2022_dollar / tickets_sold) |&gt;\n  ggplot(aes(x = year, y = cost_per)) +\n  geom_point() +\n  geom_smooth(method = \"lm\")"
  },
  {
    "objectID": "index.html#spotify",
    "href": "index.html#spotify",
    "title": "Taylor Swift’s Tour in the Pantheon of Music",
    "section": "Spotify",
    "text": "Spotify\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMonthly Listeners\n101M\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFollowers\n89M\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlaylists\n64.2K\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlaylist Reach\n1.11B\n\n\n\n\n\n\n\n\n\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus eget sem in leo pharetra rhoncus in a felis. Etiam ligula elit, euismod in gravida in, fermentum sed ligula."
  }
]